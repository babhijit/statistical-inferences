{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "def read_dataset():\n",
    "    df = pd.read_csv(\"./dataset/sonar.csv\")\n",
    "    print(len(df.columns))\n",
    "    X = df[df.columns[1:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    #Encode the dependent variable\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return (X, Y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_points(features, labels):\n",
    "    normal = np.where(labels == 0)\n",
    "    outliers = np.where(labels == 1)\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    plt.plot(features[normal, 0], features[normal, 1], 'bx')\n",
    "    plt.plot(features[outliers, 0], features[outliers, 1], 'ro')\n",
    "    plt.xlabel('Latency (ms)')\n",
    "    plt.ylabel('Throughput (mb/s)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "(207, 59)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAHjCAYAAAB8R1jMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1af05292588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y, y = read_dataset()\n",
    "#plot the features and the labels\n",
    "plot_points(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle the dataset to mix up the rows.\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "#convert the dataset into train and test part\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 59)\n",
      "(165, 2)\n",
      "(42, 59)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your Network Hyper Parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters for basic MNIST\n",
    "learning_rate = 0.1\n",
    "training_epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 59\n",
    "n_hidden_1 = 100 \n",
    "n_hidden_2 = 100\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_1 (Dense)              (None, 100)               6000      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 6,202\n",
      "Trainable params: 6,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu',  input_shape=(n_input,), name = \"Dense_1\"))\n",
    "\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 165 samples, validate on 42 samples\n",
      "Epoch 1/1000\n",
      "165/165 [==============================] - 1s - loss: 0.7638 - acc: 0.4242 - val_loss: 0.6952 - val_acc: 0.5714\n",
      "Epoch 2/1000\n",
      "165/165 [==============================] - 0s - loss: 0.7425 - acc: 0.4303 - val_loss: 0.6989 - val_acc: 0.4286\n",
      "Epoch 3/1000\n",
      "165/165 [==============================] - 0s - loss: 0.7274 - acc: 0.4000 - val_loss: 0.7036 - val_acc: 0.4524\n",
      "Epoch 4/1000\n",
      "165/165 [==============================] - 0s - loss: 0.7176 - acc: 0.3879 - val_loss: 0.7076 - val_acc: 0.4048\n",
      "Epoch 5/1000\n",
      "165/165 [==============================] - 0s - loss: 0.7090 - acc: 0.4061 - val_loss: 0.7129 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "165/165 [==============================] - 0s - loss: 0.7026 - acc: 0.4667 - val_loss: 0.7170 - val_acc: 0.3571\n",
      "Epoch 7/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6974 - acc: 0.4788 - val_loss: 0.7216 - val_acc: 0.3810\n",
      "Epoch 8/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6932 - acc: 0.5273 - val_loss: 0.7260 - val_acc: 0.3571\n",
      "Epoch 9/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6908 - acc: 0.5394 - val_loss: 0.7318 - val_acc: 0.4286\n",
      "Epoch 10/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6866 - acc: 0.5697 - val_loss: 0.7349 - val_acc: 0.4286\n",
      "Epoch 11/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6856 - acc: 0.5879 - val_loss: 0.7353 - val_acc: 0.4048\n",
      "Epoch 12/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6831 - acc: 0.5818 - val_loss: 0.7371 - val_acc: 0.4048\n",
      "Epoch 13/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6813 - acc: 0.5818 - val_loss: 0.7391 - val_acc: 0.4048\n",
      "Epoch 14/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6798 - acc: 0.6000 - val_loss: 0.7404 - val_acc: 0.4048\n",
      "Epoch 15/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6786 - acc: 0.5879 - val_loss: 0.7428 - val_acc: 0.4286\n",
      "Epoch 16/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6770 - acc: 0.5879 - val_loss: 0.7434 - val_acc: 0.4286\n",
      "Epoch 17/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6759 - acc: 0.5939 - val_loss: 0.7447 - val_acc: 0.4286\n",
      "Epoch 18/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6746 - acc: 0.5879 - val_loss: 0.7449 - val_acc: 0.4286\n",
      "Epoch 19/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6736 - acc: 0.5939 - val_loss: 0.7446 - val_acc: 0.4286\n",
      "Epoch 20/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6726 - acc: 0.5939 - val_loss: 0.7444 - val_acc: 0.4286\n",
      "Epoch 21/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6720 - acc: 0.5939 - val_loss: 0.7427 - val_acc: 0.4286\n",
      "Epoch 22/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6708 - acc: 0.5939 - val_loss: 0.7435 - val_acc: 0.4286\n",
      "Epoch 23/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6697 - acc: 0.6000 - val_loss: 0.7436 - val_acc: 0.4286\n",
      "Epoch 24/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6698 - acc: 0.6000 - val_loss: 0.7457 - val_acc: 0.4048\n",
      "Epoch 25/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6679 - acc: 0.6000 - val_loss: 0.7444 - val_acc: 0.4048\n",
      "Epoch 26/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6670 - acc: 0.6000 - val_loss: 0.7438 - val_acc: 0.4048\n",
      "Epoch 27/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6663 - acc: 0.6000 - val_loss: 0.7439 - val_acc: 0.4048\n",
      "Epoch 28/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6653 - acc: 0.6000 - val_loss: 0.7426 - val_acc: 0.4048\n",
      "Epoch 29/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6646 - acc: 0.6000 - val_loss: 0.7424 - val_acc: 0.4048\n",
      "Epoch 30/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6638 - acc: 0.6061 - val_loss: 0.7421 - val_acc: 0.4048\n",
      "Epoch 31/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6631 - acc: 0.6000 - val_loss: 0.7416 - val_acc: 0.4048\n",
      "Epoch 32/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6621 - acc: 0.6061 - val_loss: 0.7402 - val_acc: 0.4048\n",
      "Epoch 33/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6613 - acc: 0.6061 - val_loss: 0.7381 - val_acc: 0.4048\n",
      "Epoch 34/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6604 - acc: 0.6061 - val_loss: 0.7371 - val_acc: 0.4048\n",
      "Epoch 35/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6597 - acc: 0.6061 - val_loss: 0.7356 - val_acc: 0.4048\n",
      "Epoch 36/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6593 - acc: 0.6121 - val_loss: 0.7333 - val_acc: 0.4048\n",
      "Epoch 37/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6586 - acc: 0.6061 - val_loss: 0.7343 - val_acc: 0.4048\n",
      "Epoch 38/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6580 - acc: 0.6182 - val_loss: 0.7356 - val_acc: 0.4048\n",
      "Epoch 39/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6567 - acc: 0.6121 - val_loss: 0.7347 - val_acc: 0.4048\n",
      "Epoch 40/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6560 - acc: 0.6121 - val_loss: 0.7329 - val_acc: 0.4048\n",
      "Epoch 41/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6554 - acc: 0.6121 - val_loss: 0.7307 - val_acc: 0.4048\n",
      "Epoch 42/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6546 - acc: 0.6182 - val_loss: 0.7288 - val_acc: 0.4048\n",
      "Epoch 43/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6537 - acc: 0.6182 - val_loss: 0.7283 - val_acc: 0.4048\n",
      "Epoch 44/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6531 - acc: 0.6182 - val_loss: 0.7265 - val_acc: 0.4048\n",
      "Epoch 45/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6531 - acc: 0.6182 - val_loss: 0.7284 - val_acc: 0.4048\n",
      "Epoch 46/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6515 - acc: 0.6121 - val_loss: 0.7275 - val_acc: 0.4048\n",
      "Epoch 47/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6509 - acc: 0.6182 - val_loss: 0.7276 - val_acc: 0.4048\n",
      "Epoch 48/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6502 - acc: 0.6121 - val_loss: 0.7262 - val_acc: 0.4048\n",
      "Epoch 49/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6496 - acc: 0.6121 - val_loss: 0.7262 - val_acc: 0.4048\n",
      "Epoch 50/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6489 - acc: 0.6121 - val_loss: 0.7246 - val_acc: 0.4048\n",
      "Epoch 51/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6482 - acc: 0.6182 - val_loss: 0.7240 - val_acc: 0.4048\n",
      "Epoch 52/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6476 - acc: 0.6182 - val_loss: 0.7239 - val_acc: 0.4048\n",
      "Epoch 53/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6471 - acc: 0.6182 - val_loss: 0.7219 - val_acc: 0.4048\n",
      "Epoch 54/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6464 - acc: 0.6182 - val_loss: 0.7202 - val_acc: 0.4048\n",
      "Epoch 55/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6456 - acc: 0.6303 - val_loss: 0.7197 - val_acc: 0.4048\n",
      "Epoch 56/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6450 - acc: 0.6303 - val_loss: 0.7184 - val_acc: 0.4048\n",
      "Epoch 57/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6443 - acc: 0.6303 - val_loss: 0.7179 - val_acc: 0.4048\n",
      "Epoch 58/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6444 - acc: 0.6303 - val_loss: 0.7152 - val_acc: 0.4048\n",
      "Epoch 59/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6431 - acc: 0.6364 - val_loss: 0.7149 - val_acc: 0.4048\n",
      "Epoch 60/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6425 - acc: 0.6364 - val_loss: 0.7149 - val_acc: 0.4048\n",
      "Epoch 61/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6422 - acc: 0.6364 - val_loss: 0.7161 - val_acc: 0.4048\n",
      "Epoch 62/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6413 - acc: 0.6364 - val_loss: 0.7152 - val_acc: 0.4048\n",
      "Epoch 63/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6409 - acc: 0.6424 - val_loss: 0.7159 - val_acc: 0.4048\n",
      "Epoch 64/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6402 - acc: 0.6364 - val_loss: 0.7143 - val_acc: 0.4048\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.6395 - acc: 0.6424 - val_loss: 0.7137 - val_acc: 0.4048\n",
      "Epoch 66/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6403 - acc: 0.6424 - val_loss: 0.7101 - val_acc: 0.4048\n",
      "Epoch 67/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6385 - acc: 0.6545 - val_loss: 0.7106 - val_acc: 0.4048\n",
      "Epoch 68/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6380 - acc: 0.6545 - val_loss: 0.7109 - val_acc: 0.4048\n",
      "Epoch 69/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6385 - acc: 0.6545 - val_loss: 0.7132 - val_acc: 0.4048\n",
      "Epoch 70/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6371 - acc: 0.6545 - val_loss: 0.7111 - val_acc: 0.4048\n",
      "Epoch 71/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6364 - acc: 0.6545 - val_loss: 0.7110 - val_acc: 0.4048\n",
      "Epoch 72/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6363 - acc: 0.6545 - val_loss: 0.7085 - val_acc: 0.4286\n",
      "Epoch 73/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6353 - acc: 0.6545 - val_loss: 0.7086 - val_acc: 0.4286\n",
      "Epoch 74/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6348 - acc: 0.6545 - val_loss: 0.7080 - val_acc: 0.4286\n",
      "Epoch 75/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6343 - acc: 0.6545 - val_loss: 0.7074 - val_acc: 0.4286\n",
      "Epoch 76/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6338 - acc: 0.6606 - val_loss: 0.7068 - val_acc: 0.4286\n",
      "Epoch 77/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6333 - acc: 0.6606 - val_loss: 0.7063 - val_acc: 0.4524\n",
      "Epoch 78/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6330 - acc: 0.6606 - val_loss: 0.7070 - val_acc: 0.4524\n",
      "Epoch 79/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6325 - acc: 0.6667 - val_loss: 0.7072 - val_acc: 0.4524\n",
      "Epoch 80/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6319 - acc: 0.6545 - val_loss: 0.7062 - val_acc: 0.4524\n",
      "Epoch 81/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6321 - acc: 0.6606 - val_loss: 0.7079 - val_acc: 0.4524\n",
      "Epoch 82/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6310 - acc: 0.6606 - val_loss: 0.7078 - val_acc: 0.4524\n",
      "Epoch 83/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6304 - acc: 0.6545 - val_loss: 0.7065 - val_acc: 0.4524\n",
      "Epoch 84/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6415 - acc: 0.660 - 0s - loss: 0.6302 - acc: 0.6667 - val_loss: 0.7072 - val_acc: 0.4524\n",
      "Epoch 85/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6294 - acc: 0.6667 - val_loss: 0.7064 - val_acc: 0.4524\n",
      "Epoch 86/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6291 - acc: 0.6667 - val_loss: 0.7046 - val_acc: 0.4524\n",
      "Epoch 87/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6287 - acc: 0.6667 - val_loss: 0.7028 - val_acc: 0.4524\n",
      "Epoch 88/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6293 - acc: 0.6667 - val_loss: 0.6993 - val_acc: 0.4524\n",
      "Epoch 89/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6276 - acc: 0.6727 - val_loss: 0.6989 - val_acc: 0.4524\n",
      "Epoch 90/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6275 - acc: 0.6788 - val_loss: 0.6973 - val_acc: 0.4524\n",
      "Epoch 91/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6270 - acc: 0.6727 - val_loss: 0.6989 - val_acc: 0.4524\n",
      "Epoch 92/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6264 - acc: 0.6727 - val_loss: 0.7000 - val_acc: 0.4524\n",
      "Epoch 93/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6259 - acc: 0.6667 - val_loss: 0.7007 - val_acc: 0.4524\n",
      "Epoch 94/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6253 - acc: 0.6727 - val_loss: 0.7003 - val_acc: 0.4524\n",
      "Epoch 95/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6249 - acc: 0.6727 - val_loss: 0.6988 - val_acc: 0.4524\n",
      "Epoch 96/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6253 - acc: 0.6727 - val_loss: 0.6957 - val_acc: 0.4524\n",
      "Epoch 97/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6241 - acc: 0.6727 - val_loss: 0.6944 - val_acc: 0.4762\n",
      "Epoch 98/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6235 - acc: 0.6848 - val_loss: 0.6950 - val_acc: 0.4762\n",
      "Epoch 99/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6232 - acc: 0.6848 - val_loss: 0.6937 - val_acc: 0.4762\n",
      "Epoch 100/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6226 - acc: 0.6848 - val_loss: 0.6934 - val_acc: 0.4762\n",
      "Epoch 101/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6222 - acc: 0.6848 - val_loss: 0.6924 - val_acc: 0.4762\n",
      "Epoch 102/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6224 - acc: 0.6848 - val_loss: 0.6949 - val_acc: 0.4524\n",
      "Epoch 103/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6213 - acc: 0.6848 - val_loss: 0.6938 - val_acc: 0.4762\n",
      "Epoch 104/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6207 - acc: 0.6848 - val_loss: 0.6937 - val_acc: 0.4762\n",
      "Epoch 105/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6206 - acc: 0.6848 - val_loss: 0.6948 - val_acc: 0.4524\n",
      "Epoch 106/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6204 - acc: 0.6848 - val_loss: 0.6924 - val_acc: 0.4762\n",
      "Epoch 107/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6195 - acc: 0.6848 - val_loss: 0.6921 - val_acc: 0.4762\n",
      "Epoch 108/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6190 - acc: 0.6909 - val_loss: 0.6923 - val_acc: 0.4762\n",
      "Epoch 109/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6186 - acc: 0.6848 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 110/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6182 - acc: 0.6909 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 111/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6178 - acc: 0.6909 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 112/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6174 - acc: 0.6909 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 113/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6170 - acc: 0.6909 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 114/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6167 - acc: 0.6909 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 115/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6164 - acc: 0.6909 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 116/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6158 - acc: 0.6909 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 117/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6153 - acc: 0.6909 - val_loss: 0.6898 - val_acc: 0.5000\n",
      "Epoch 118/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6151 - acc: 0.6970 - val_loss: 0.6906 - val_acc: 0.5000\n",
      "Epoch 119/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6145 - acc: 0.6909 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 120/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6152 - acc: 0.6909 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 121/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6137 - acc: 0.6909 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 122/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6134 - acc: 0.6909 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 123/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6128 - acc: 0.6909 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 124/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6124 - acc: 0.6970 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 125/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6121 - acc: 0.6970 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 126/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6117 - acc: 0.6970 - val_loss: 0.6867 - val_acc: 0.5238\n",
      "Epoch 127/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6116 - acc: 0.6970 - val_loss: 0.6877 - val_acc: 0.5000\n",
      "Epoch 128/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6110 - acc: 0.6970 - val_loss: 0.6860 - val_acc: 0.5238\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.6105 - acc: 0.7091 - val_loss: 0.6865 - val_acc: 0.5238\n",
      "Epoch 130/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6102 - acc: 0.6970 - val_loss: 0.6845 - val_acc: 0.5238\n",
      "Epoch 131/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6099 - acc: 0.7152 - val_loss: 0.6855 - val_acc: 0.5238\n",
      "Epoch 132/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6093 - acc: 0.7030 - val_loss: 0.6850 - val_acc: 0.5238\n",
      "Epoch 133/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6093 - acc: 0.7030 - val_loss: 0.6862 - val_acc: 0.5238\n",
      "Epoch 134/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6086 - acc: 0.6970 - val_loss: 0.6843 - val_acc: 0.5238\n",
      "Epoch 135/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6081 - acc: 0.7152 - val_loss: 0.6840 - val_acc: 0.5238\n",
      "Epoch 136/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6077 - acc: 0.7152 - val_loss: 0.6826 - val_acc: 0.5238\n",
      "Epoch 137/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6074 - acc: 0.7152 - val_loss: 0.6812 - val_acc: 0.5238\n",
      "Epoch 138/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6074 - acc: 0.7091 - val_loss: 0.6788 - val_acc: 0.5238\n",
      "Epoch 139/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6071 - acc: 0.7333 - val_loss: 0.6808 - val_acc: 0.5238\n",
      "Epoch 140/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6063 - acc: 0.7212 - val_loss: 0.6793 - val_acc: 0.5238\n",
      "Epoch 141/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6058 - acc: 0.7333 - val_loss: 0.6799 - val_acc: 0.5238\n",
      "Epoch 142/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6058 - acc: 0.7333 - val_loss: 0.6813 - val_acc: 0.5238\n",
      "Epoch 143/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6051 - acc: 0.7273 - val_loss: 0.6814 - val_acc: 0.5238\n",
      "Epoch 144/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6046 - acc: 0.7212 - val_loss: 0.6808 - val_acc: 0.5238\n",
      "Epoch 145/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6042 - acc: 0.7273 - val_loss: 0.6795 - val_acc: 0.5238\n",
      "Epoch 146/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6044 - acc: 0.7212 - val_loss: 0.6765 - val_acc: 0.5238\n",
      "Epoch 147/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6038 - acc: 0.7333 - val_loss: 0.6744 - val_acc: 0.5476\n",
      "Epoch 148/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6030 - acc: 0.7333 - val_loss: 0.6744 - val_acc: 0.5476\n",
      "Epoch 149/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6029 - acc: 0.7333 - val_loss: 0.6730 - val_acc: 0.5476\n",
      "Epoch 150/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6028 - acc: 0.7333 - val_loss: 0.6751 - val_acc: 0.5476\n",
      "Epoch 151/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6019 - acc: 0.7333 - val_loss: 0.6747 - val_acc: 0.5476\n",
      "Epoch 152/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6016 - acc: 0.7333 - val_loss: 0.6754 - val_acc: 0.5476\n",
      "Epoch 153/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6013 - acc: 0.7333 - val_loss: 0.6754 - val_acc: 0.5476\n",
      "Epoch 154/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6010 - acc: 0.7333 - val_loss: 0.6763 - val_acc: 0.5238\n",
      "Epoch 155/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6005 - acc: 0.7333 - val_loss: 0.6763 - val_acc: 0.5238\n",
      "Epoch 156/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6006 - acc: 0.7333 - val_loss: 0.6775 - val_acc: 0.5238\n",
      "Epoch 157/1000\n",
      "165/165 [==============================] - 0s - loss: 0.6009 - acc: 0.7333 - val_loss: 0.6732 - val_acc: 0.5476\n",
      "Epoch 158/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5993 - acc: 0.7333 - val_loss: 0.6732 - val_acc: 0.5476\n",
      "Epoch 159/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5992 - acc: 0.7333 - val_loss: 0.6709 - val_acc: 0.5476\n",
      "Epoch 160/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5987 - acc: 0.7333 - val_loss: 0.6692 - val_acc: 0.5476\n",
      "Epoch 161/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5983 - acc: 0.7333 - val_loss: 0.6703 - val_acc: 0.5476\n",
      "Epoch 162/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5978 - acc: 0.7333 - val_loss: 0.6703 - val_acc: 0.5476\n",
      "Epoch 163/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5974 - acc: 0.7333 - val_loss: 0.6695 - val_acc: 0.5476\n",
      "Epoch 164/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5976 - acc: 0.7333 - val_loss: 0.6714 - val_acc: 0.5476\n",
      "Epoch 165/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5967 - acc: 0.7333 - val_loss: 0.6710 - val_acc: 0.5476\n",
      "Epoch 166/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5963 - acc: 0.7333 - val_loss: 0.6707 - val_acc: 0.5476\n",
      "Epoch 167/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5967 - acc: 0.7394 - val_loss: 0.6724 - val_acc: 0.5476\n",
      "Epoch 168/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5957 - acc: 0.7333 - val_loss: 0.6702 - val_acc: 0.5476\n",
      "Epoch 169/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5954 - acc: 0.7333 - val_loss: 0.6681 - val_acc: 0.5476\n",
      "Epoch 170/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5948 - acc: 0.7333 - val_loss: 0.6674 - val_acc: 0.5476\n",
      "Epoch 171/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5948 - acc: 0.7333 - val_loss: 0.6685 - val_acc: 0.5476\n",
      "Epoch 172/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5941 - acc: 0.7333 - val_loss: 0.6677 - val_acc: 0.5476\n",
      "Epoch 173/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5937 - acc: 0.7333 - val_loss: 0.6667 - val_acc: 0.5714\n",
      "Epoch 174/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5934 - acc: 0.7333 - val_loss: 0.6657 - val_acc: 0.5714\n",
      "Epoch 175/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6023 - acc: 0.730 - 0s - loss: 0.5930 - acc: 0.7394 - val_loss: 0.6655 - val_acc: 0.5714\n",
      "Epoch 176/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5929 - acc: 0.7455 - val_loss: 0.6666 - val_acc: 0.5714\n",
      "Epoch 177/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5929 - acc: 0.7333 - val_loss: 0.6635 - val_acc: 0.5714\n",
      "Epoch 178/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5919 - acc: 0.7455 - val_loss: 0.6628 - val_acc: 0.5714\n",
      "Epoch 179/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5916 - acc: 0.7455 - val_loss: 0.6621 - val_acc: 0.5714\n",
      "Epoch 180/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5922 - acc: 0.7394 - val_loss: 0.6647 - val_acc: 0.5714\n",
      "Epoch 181/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5909 - acc: 0.7333 - val_loss: 0.6634 - val_acc: 0.5714\n",
      "Epoch 182/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5906 - acc: 0.7394 - val_loss: 0.6618 - val_acc: 0.5714\n",
      "Epoch 183/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5901 - acc: 0.7455 - val_loss: 0.6611 - val_acc: 0.5714\n",
      "Epoch 184/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5900 - acc: 0.7455 - val_loss: 0.6595 - val_acc: 0.5714\n",
      "Epoch 185/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5896 - acc: 0.7394 - val_loss: 0.6583 - val_acc: 0.5714\n",
      "Epoch 186/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5892 - acc: 0.7515 - val_loss: 0.6594 - val_acc: 0.5714\n",
      "Epoch 187/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5888 - acc: 0.7515 - val_loss: 0.6583 - val_acc: 0.5714\n",
      "Epoch 188/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5884 - acc: 0.7455 - val_loss: 0.6588 - val_acc: 0.5714\n",
      "Epoch 189/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5880 - acc: 0.7515 - val_loss: 0.6588 - val_acc: 0.5714\n",
      "Epoch 190/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5887 - acc: 0.7394 - val_loss: 0.6615 - val_acc: 0.5714\n",
      "Epoch 191/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5874 - acc: 0.7455 - val_loss: 0.6596 - val_acc: 0.5714\n",
      "Epoch 192/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5872 - acc: 0.7455 - val_loss: 0.6574 - val_acc: 0.5714\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.5867 - acc: 0.7515 - val_loss: 0.6558 - val_acc: 0.6190\n",
      "Epoch 194/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5862 - acc: 0.7515 - val_loss: 0.6560 - val_acc: 0.5714\n",
      "Epoch 195/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5858 - acc: 0.7515 - val_loss: 0.6559 - val_acc: 0.5952\n",
      "Epoch 196/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5855 - acc: 0.7515 - val_loss: 0.6563 - val_acc: 0.5714\n",
      "Epoch 197/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5852 - acc: 0.7515 - val_loss: 0.6562 - val_acc: 0.5714\n",
      "Epoch 198/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5849 - acc: 0.7576 - val_loss: 0.6550 - val_acc: 0.5952\n",
      "Epoch 199/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5845 - acc: 0.7515 - val_loss: 0.6539 - val_acc: 0.6190\n",
      "Epoch 200/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5842 - acc: 0.7515 - val_loss: 0.6545 - val_acc: 0.5952\n",
      "Epoch 201/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5838 - acc: 0.7515 - val_loss: 0.6531 - val_acc: 0.6190\n",
      "Epoch 202/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5835 - acc: 0.7515 - val_loss: 0.6532 - val_acc: 0.6190\n",
      "Epoch 203/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5831 - acc: 0.7515 - val_loss: 0.6524 - val_acc: 0.6190\n",
      "Epoch 204/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5827 - acc: 0.7515 - val_loss: 0.6524 - val_acc: 0.6190\n",
      "Epoch 205/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5823 - acc: 0.7515 - val_loss: 0.6517 - val_acc: 0.6190\n",
      "Epoch 206/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5820 - acc: 0.7515 - val_loss: 0.6515 - val_acc: 0.6190\n",
      "Epoch 207/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5817 - acc: 0.7515 - val_loss: 0.6506 - val_acc: 0.6190\n",
      "Epoch 208/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5815 - acc: 0.7515 - val_loss: 0.6519 - val_acc: 0.6190\n",
      "Epoch 209/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5809 - acc: 0.7515 - val_loss: 0.6514 - val_acc: 0.6190\n",
      "Epoch 210/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5806 - acc: 0.7515 - val_loss: 0.6516 - val_acc: 0.6190\n",
      "Epoch 211/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5809 - acc: 0.7515 - val_loss: 0.6533 - val_acc: 0.5952\n",
      "Epoch 212/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5804 - acc: 0.7515 - val_loss: 0.6543 - val_acc: 0.5952\n",
      "Epoch 213/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5800 - acc: 0.7515 - val_loss: 0.6549 - val_acc: 0.5952\n",
      "Epoch 214/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5800 - acc: 0.7576 - val_loss: 0.6512 - val_acc: 0.5952\n",
      "Epoch 215/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5794 - acc: 0.7576 - val_loss: 0.6526 - val_acc: 0.5952\n",
      "Epoch 216/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5786 - acc: 0.7576 - val_loss: 0.6512 - val_acc: 0.5952\n",
      "Epoch 217/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5783 - acc: 0.7576 - val_loss: 0.6513 - val_acc: 0.5952\n",
      "Epoch 218/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5780 - acc: 0.7576 - val_loss: 0.6491 - val_acc: 0.6190\n",
      "Epoch 219/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5776 - acc: 0.7515 - val_loss: 0.6477 - val_acc: 0.6190\n",
      "Epoch 220/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5775 - acc: 0.7515 - val_loss: 0.6454 - val_acc: 0.6190\n",
      "Epoch 221/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5769 - acc: 0.7515 - val_loss: 0.6447 - val_acc: 0.6190\n",
      "Epoch 222/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5765 - acc: 0.7515 - val_loss: 0.6444 - val_acc: 0.6190\n",
      "Epoch 223/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5773 - acc: 0.7515 - val_loss: 0.6474 - val_acc: 0.6190\n",
      "Epoch 224/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5760 - acc: 0.7515 - val_loss: 0.6455 - val_acc: 0.6190\n",
      "Epoch 225/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5755 - acc: 0.7515 - val_loss: 0.6444 - val_acc: 0.6190\n",
      "Epoch 226/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5762 - acc: 0.7394 - val_loss: 0.6471 - val_acc: 0.6190\n",
      "Epoch 227/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5749 - acc: 0.7515 - val_loss: 0.6458 - val_acc: 0.6190\n",
      "Epoch 228/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5645 - acc: 0.790 - 0s - loss: 0.5747 - acc: 0.7576 - val_loss: 0.6437 - val_acc: 0.6190\n",
      "Epoch 229/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5742 - acc: 0.7515 - val_loss: 0.6433 - val_acc: 0.6190\n",
      "Epoch 230/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5740 - acc: 0.7515 - val_loss: 0.6418 - val_acc: 0.6190\n",
      "Epoch 231/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5736 - acc: 0.7515 - val_loss: 0.6423 - val_acc: 0.6190\n",
      "Epoch 232/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5732 - acc: 0.7515 - val_loss: 0.6421 - val_acc: 0.6190\n",
      "Epoch 233/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5729 - acc: 0.7515 - val_loss: 0.6413 - val_acc: 0.6190\n",
      "Epoch 234/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5725 - acc: 0.7515 - val_loss: 0.6409 - val_acc: 0.6190\n",
      "Epoch 235/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5725 - acc: 0.7515 - val_loss: 0.6422 - val_acc: 0.6190\n",
      "Epoch 236/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5722 - acc: 0.7576 - val_loss: 0.6397 - val_acc: 0.6190\n",
      "Epoch 237/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5721 - acc: 0.7455 - val_loss: 0.6418 - val_acc: 0.6190\n",
      "Epoch 238/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5713 - acc: 0.7515 - val_loss: 0.6400 - val_acc: 0.6190\n",
      "Epoch 239/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5713 - acc: 0.7515 - val_loss: 0.6415 - val_acc: 0.6190\n",
      "Epoch 240/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5705 - acc: 0.7515 - val_loss: 0.6411 - val_acc: 0.6190\n",
      "Epoch 241/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5702 - acc: 0.7515 - val_loss: 0.6405 - val_acc: 0.6190\n",
      "Epoch 242/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5698 - acc: 0.7515 - val_loss: 0.6404 - val_acc: 0.6190\n",
      "Epoch 243/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5696 - acc: 0.7515 - val_loss: 0.6406 - val_acc: 0.6190\n",
      "Epoch 244/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5694 - acc: 0.7515 - val_loss: 0.6384 - val_acc: 0.6190\n",
      "Epoch 245/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5689 - acc: 0.7515 - val_loss: 0.6373 - val_acc: 0.6190\n",
      "Epoch 246/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5686 - acc: 0.7576 - val_loss: 0.6361 - val_acc: 0.6190\n",
      "Epoch 247/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5685 - acc: 0.7455 - val_loss: 0.6342 - val_acc: 0.6190\n",
      "Epoch 248/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5682 - acc: 0.7576 - val_loss: 0.6326 - val_acc: 0.6429\n",
      "Epoch 249/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5676 - acc: 0.7455 - val_loss: 0.6336 - val_acc: 0.6429\n",
      "Epoch 250/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5672 - acc: 0.7515 - val_loss: 0.6340 - val_acc: 0.6190\n",
      "Epoch 251/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5673 - acc: 0.7515 - val_loss: 0.6321 - val_acc: 0.6429\n",
      "Epoch 252/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5521 - acc: 0.770 - 0s - loss: 0.5666 - acc: 0.7515 - val_loss: 0.6320 - val_acc: 0.6429\n",
      "Epoch 253/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5664 - acc: 0.7515 - val_loss: 0.6311 - val_acc: 0.6429\n",
      "Epoch 254/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5659 - acc: 0.7515 - val_loss: 0.6320 - val_acc: 0.6429\n",
      "Epoch 255/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5662 - acc: 0.7576 - val_loss: 0.6296 - val_acc: 0.6429\n",
      "Epoch 256/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5653 - acc: 0.7515 - val_loss: 0.6292 - val_acc: 0.6429\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.5650 - acc: 0.7515 - val_loss: 0.6288 - val_acc: 0.6429\n",
      "Epoch 258/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5649 - acc: 0.7515 - val_loss: 0.6306 - val_acc: 0.6429\n",
      "Epoch 259/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5643 - acc: 0.7515 - val_loss: 0.6302 - val_acc: 0.6429\n",
      "Epoch 260/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5640 - acc: 0.7515 - val_loss: 0.6307 - val_acc: 0.6429\n",
      "Epoch 261/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5637 - acc: 0.7515 - val_loss: 0.6297 - val_acc: 0.6429\n",
      "Epoch 262/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5634 - acc: 0.7515 - val_loss: 0.6288 - val_acc: 0.6429\n",
      "Epoch 263/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5630 - acc: 0.7515 - val_loss: 0.6286 - val_acc: 0.6429\n",
      "Epoch 264/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5626 - acc: 0.7515 - val_loss: 0.6288 - val_acc: 0.6429\n",
      "Epoch 265/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5624 - acc: 0.7515 - val_loss: 0.6276 - val_acc: 0.6429\n",
      "Epoch 266/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5620 - acc: 0.7515 - val_loss: 0.6280 - val_acc: 0.6429\n",
      "Epoch 267/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5619 - acc: 0.7515 - val_loss: 0.6294 - val_acc: 0.6429\n",
      "Epoch 268/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5625 - acc: 0.7455 - val_loss: 0.6323 - val_acc: 0.6429\n",
      "Epoch 269/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5612 - acc: 0.7576 - val_loss: 0.6298 - val_acc: 0.6429\n",
      "Epoch 270/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5609 - acc: 0.7515 - val_loss: 0.6306 - val_acc: 0.6429\n",
      "Epoch 271/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5604 - acc: 0.7576 - val_loss: 0.6297 - val_acc: 0.6429\n",
      "Epoch 272/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5601 - acc: 0.7576 - val_loss: 0.6279 - val_acc: 0.6429\n",
      "Epoch 273/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5598 - acc: 0.7515 - val_loss: 0.6268 - val_acc: 0.6429\n",
      "Epoch 274/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5593 - acc: 0.7515 - val_loss: 0.6265 - val_acc: 0.6429\n",
      "Epoch 275/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5602 - acc: 0.7515 - val_loss: 0.6229 - val_acc: 0.6429\n",
      "Epoch 276/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5589 - acc: 0.7515 - val_loss: 0.6217 - val_acc: 0.6429\n",
      "Epoch 277/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5584 - acc: 0.7515 - val_loss: 0.6221 - val_acc: 0.6429\n",
      "Epoch 278/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5581 - acc: 0.7515 - val_loss: 0.6232 - val_acc: 0.6429\n",
      "Epoch 279/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5579 - acc: 0.7515 - val_loss: 0.6220 - val_acc: 0.6429\n",
      "Epoch 280/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5575 - acc: 0.7515 - val_loss: 0.6223 - val_acc: 0.6429\n",
      "Epoch 281/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5571 - acc: 0.7515 - val_loss: 0.6223 - val_acc: 0.6429\n",
      "Epoch 282/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5568 - acc: 0.7515 - val_loss: 0.6227 - val_acc: 0.6429\n",
      "Epoch 283/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5570 - acc: 0.7515 - val_loss: 0.6203 - val_acc: 0.6429\n",
      "Epoch 284/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5562 - acc: 0.7515 - val_loss: 0.6204 - val_acc: 0.6429\n",
      "Epoch 285/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5561 - acc: 0.7515 - val_loss: 0.6191 - val_acc: 0.6429\n",
      "Epoch 286/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5557 - acc: 0.7515 - val_loss: 0.6182 - val_acc: 0.6429\n",
      "Epoch 287/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5556 - acc: 0.7515 - val_loss: 0.6169 - val_acc: 0.6429\n",
      "Epoch 288/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5553 - acc: 0.7455 - val_loss: 0.6190 - val_acc: 0.6429\n",
      "Epoch 289/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5546 - acc: 0.7515 - val_loss: 0.6192 - val_acc: 0.6429\n",
      "Epoch 290/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5543 - acc: 0.7515 - val_loss: 0.6192 - val_acc: 0.6429\n",
      "Epoch 291/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5540 - acc: 0.7515 - val_loss: 0.6182 - val_acc: 0.6429\n",
      "Epoch 292/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5537 - acc: 0.7515 - val_loss: 0.6187 - val_acc: 0.6429\n",
      "Epoch 293/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5538 - acc: 0.7515 - val_loss: 0.6165 - val_acc: 0.6429\n",
      "Epoch 294/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5531 - acc: 0.7515 - val_loss: 0.6159 - val_acc: 0.6429\n",
      "Epoch 295/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5527 - acc: 0.7515 - val_loss: 0.6163 - val_acc: 0.6429\n",
      "Epoch 296/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5534 - acc: 0.7515 - val_loss: 0.6194 - val_acc: 0.6429\n",
      "Epoch 297/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5524 - acc: 0.7515 - val_loss: 0.6205 - val_acc: 0.6429\n",
      "Epoch 298/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5521 - acc: 0.7515 - val_loss: 0.6213 - val_acc: 0.6429\n",
      "Epoch 299/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5515 - acc: 0.7515 - val_loss: 0.6195 - val_acc: 0.6429\n",
      "Epoch 300/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5513 - acc: 0.7515 - val_loss: 0.6175 - val_acc: 0.6429\n",
      "Epoch 301/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5509 - acc: 0.7515 - val_loss: 0.6164 - val_acc: 0.6429\n",
      "Epoch 302/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5508 - acc: 0.7515 - val_loss: 0.6177 - val_acc: 0.6429\n",
      "Epoch 303/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5502 - acc: 0.7515 - val_loss: 0.6169 - val_acc: 0.6429\n",
      "Epoch 304/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5501 - acc: 0.7515 - val_loss: 0.6147 - val_acc: 0.6429\n",
      "Epoch 305/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5497 - acc: 0.7515 - val_loss: 0.6158 - val_acc: 0.6429\n",
      "Epoch 306/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5493 - acc: 0.7515 - val_loss: 0.6148 - val_acc: 0.6429\n",
      "Epoch 307/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5495 - acc: 0.7515 - val_loss: 0.6121 - val_acc: 0.6429\n",
      "Epoch 308/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5487 - acc: 0.7515 - val_loss: 0.6132 - val_acc: 0.6429\n",
      "Epoch 309/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5484 - acc: 0.7515 - val_loss: 0.6141 - val_acc: 0.6429\n",
      "Epoch 310/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5487 - acc: 0.7515 - val_loss: 0.6109 - val_acc: 0.6429\n",
      "Epoch 311/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5477 - acc: 0.7515 - val_loss: 0.6104 - val_acc: 0.6429\n",
      "Epoch 312/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5481 - acc: 0.7515 - val_loss: 0.6079 - val_acc: 0.6429\n",
      "Epoch 313/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5471 - acc: 0.7515 - val_loss: 0.6078 - val_acc: 0.6429\n",
      "Epoch 314/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5468 - acc: 0.7515 - val_loss: 0.6081 - val_acc: 0.6429\n",
      "Epoch 315/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5466 - acc: 0.7515 - val_loss: 0.6095 - val_acc: 0.6429\n",
      "Epoch 316/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5468 - acc: 0.7515 - val_loss: 0.6071 - val_acc: 0.6429\n",
      "Epoch 317/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5460 - acc: 0.7515 - val_loss: 0.6062 - val_acc: 0.6429\n",
      "Epoch 318/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5463 - acc: 0.7515 - val_loss: 0.6041 - val_acc: 0.6429\n",
      "Epoch 319/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5453 - acc: 0.7515 - val_loss: 0.6055 - val_acc: 0.6429\n",
      "Epoch 320/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5449 - acc: 0.7515 - val_loss: 0.6058 - val_acc: 0.6429\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.5446 - acc: 0.7515 - val_loss: 0.6061 - val_acc: 0.6429\n",
      "Epoch 322/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5443 - acc: 0.7515 - val_loss: 0.6065 - val_acc: 0.6429\n",
      "Epoch 323/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5444 - acc: 0.7515 - val_loss: 0.6047 - val_acc: 0.6429\n",
      "Epoch 324/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5437 - acc: 0.7515 - val_loss: 0.6058 - val_acc: 0.6429\n",
      "Epoch 325/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5434 - acc: 0.7515 - val_loss: 0.6067 - val_acc: 0.6429\n",
      "Epoch 326/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5430 - acc: 0.7515 - val_loss: 0.6067 - val_acc: 0.6429\n",
      "Epoch 327/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5428 - acc: 0.7515 - val_loss: 0.6054 - val_acc: 0.6429\n",
      "Epoch 328/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5424 - acc: 0.7515 - val_loss: 0.6053 - val_acc: 0.6429\n",
      "Epoch 329/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5425 - acc: 0.7515 - val_loss: 0.6075 - val_acc: 0.6429\n",
      "Epoch 330/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5418 - acc: 0.7515 - val_loss: 0.6076 - val_acc: 0.6429\n",
      "Epoch 331/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5415 - acc: 0.7515 - val_loss: 0.6062 - val_acc: 0.6429\n",
      "Epoch 332/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5411 - acc: 0.7515 - val_loss: 0.6053 - val_acc: 0.6429\n",
      "Epoch 333/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5415 - acc: 0.7515 - val_loss: 0.6023 - val_acc: 0.6429\n",
      "Epoch 334/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5405 - acc: 0.7515 - val_loss: 0.6022 - val_acc: 0.6429\n",
      "Epoch 335/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5404 - acc: 0.7515 - val_loss: 0.6037 - val_acc: 0.6429\n",
      "Epoch 336/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5399 - acc: 0.7515 - val_loss: 0.6035 - val_acc: 0.6429\n",
      "Epoch 337/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5396 - acc: 0.7515 - val_loss: 0.6024 - val_acc: 0.6429\n",
      "Epoch 338/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5396 - acc: 0.7515 - val_loss: 0.6004 - val_acc: 0.6429\n",
      "Epoch 339/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5390 - acc: 0.7515 - val_loss: 0.6002 - val_acc: 0.6429\n",
      "Epoch 340/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5388 - acc: 0.7515 - val_loss: 0.5993 - val_acc: 0.6429\n",
      "Epoch 341/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5384 - acc: 0.7515 - val_loss: 0.5998 - val_acc: 0.6429\n",
      "Epoch 342/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5381 - acc: 0.7515 - val_loss: 0.5996 - val_acc: 0.6429\n",
      "Epoch 343/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5378 - acc: 0.7515 - val_loss: 0.5991 - val_acc: 0.6429\n",
      "Epoch 344/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5374 - acc: 0.7515 - val_loss: 0.5999 - val_acc: 0.6429\n",
      "Epoch 345/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5371 - acc: 0.7515 - val_loss: 0.5995 - val_acc: 0.6429\n",
      "Epoch 346/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5368 - acc: 0.7515 - val_loss: 0.6001 - val_acc: 0.6429\n",
      "Epoch 347/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5369 - acc: 0.7515 - val_loss: 0.6020 - val_acc: 0.6429\n",
      "Epoch 348/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5365 - acc: 0.7515 - val_loss: 0.5993 - val_acc: 0.6429\n",
      "Epoch 349/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5359 - acc: 0.7515 - val_loss: 0.5984 - val_acc: 0.6429\n",
      "Epoch 350/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5356 - acc: 0.7515 - val_loss: 0.5975 - val_acc: 0.6429\n",
      "Epoch 351/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5354 - acc: 0.7515 - val_loss: 0.5963 - val_acc: 0.6429\n",
      "Epoch 352/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5350 - acc: 0.7515 - val_loss: 0.5972 - val_acc: 0.6429\n",
      "Epoch 353/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5353 - acc: 0.7576 - val_loss: 0.5998 - val_acc: 0.6429\n",
      "Epoch 354/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5343 - acc: 0.7515 - val_loss: 0.5993 - val_acc: 0.6429\n",
      "Epoch 355/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5341 - acc: 0.7515 - val_loss: 0.5978 - val_acc: 0.6429\n",
      "Epoch 356/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5339 - acc: 0.7515 - val_loss: 0.5991 - val_acc: 0.6429\n",
      "Epoch 357/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5334 - acc: 0.7515 - val_loss: 0.5981 - val_acc: 0.6429\n",
      "Epoch 358/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5333 - acc: 0.7515 - val_loss: 0.5987 - val_acc: 0.6429\n",
      "Epoch 359/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5329 - acc: 0.7515 - val_loss: 0.5971 - val_acc: 0.6429\n",
      "Epoch 360/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5327 - acc: 0.7515 - val_loss: 0.5954 - val_acc: 0.6429\n",
      "Epoch 361/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5323 - acc: 0.7576 - val_loss: 0.5945 - val_acc: 0.6429\n",
      "Epoch 362/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5319 - acc: 0.7576 - val_loss: 0.5945 - val_acc: 0.6429\n",
      "Epoch 363/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5317 - acc: 0.7636 - val_loss: 0.5937 - val_acc: 0.6429\n",
      "Epoch 364/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5316 - acc: 0.7636 - val_loss: 0.5918 - val_acc: 0.6429\n",
      "Epoch 365/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5311 - acc: 0.7576 - val_loss: 0.5922 - val_acc: 0.6429\n",
      "Epoch 366/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5315 - acc: 0.7636 - val_loss: 0.5951 - val_acc: 0.6429\n",
      "Epoch 367/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5310 - acc: 0.7515 - val_loss: 0.5921 - val_acc: 0.6429\n",
      "Epoch 368/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5244 - acc: 0.760 - 0s - loss: 0.5302 - acc: 0.7576 - val_loss: 0.5918 - val_acc: 0.6429\n",
      "Epoch 369/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5300 - acc: 0.7576 - val_loss: 0.5905 - val_acc: 0.6429\n",
      "Epoch 370/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5296 - acc: 0.7576 - val_loss: 0.5901 - val_acc: 0.6429\n",
      "Epoch 371/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5298 - acc: 0.7515 - val_loss: 0.5880 - val_acc: 0.6429\n",
      "Epoch 372/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5290 - acc: 0.7576 - val_loss: 0.5886 - val_acc: 0.6429\n",
      "Epoch 373/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5287 - acc: 0.7576 - val_loss: 0.5887 - val_acc: 0.6429\n",
      "Epoch 374/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5284 - acc: 0.7576 - val_loss: 0.5884 - val_acc: 0.6429\n",
      "Epoch 375/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5282 - acc: 0.7576 - val_loss: 0.5878 - val_acc: 0.6429\n",
      "Epoch 376/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5278 - acc: 0.7576 - val_loss: 0.5877 - val_acc: 0.6429\n",
      "Epoch 377/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5276 - acc: 0.7576 - val_loss: 0.5886 - val_acc: 0.6429\n",
      "Epoch 378/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5273 - acc: 0.7576 - val_loss: 0.5885 - val_acc: 0.6429\n",
      "Epoch 379/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5273 - acc: 0.7697 - val_loss: 0.5906 - val_acc: 0.6429\n",
      "Epoch 380/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5468 - acc: 0.730 - 0s - loss: 0.5269 - acc: 0.7636 - val_loss: 0.5885 - val_acc: 0.6429\n",
      "Epoch 381/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5266 - acc: 0.7636 - val_loss: 0.5900 - val_acc: 0.6429\n",
      "Epoch 382/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5261 - acc: 0.7576 - val_loss: 0.5898 - val_acc: 0.6429\n",
      "Epoch 383/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5259 - acc: 0.7636 - val_loss: 0.5883 - val_acc: 0.6429\n",
      "Epoch 384/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5256 - acc: 0.7576 - val_loss: 0.5879 - val_acc: 0.6429\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.5254 - acc: 0.7576 - val_loss: 0.5864 - val_acc: 0.6429\n",
      "Epoch 386/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5257 - acc: 0.7576 - val_loss: 0.5836 - val_acc: 0.6429\n",
      "Epoch 387/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5254 - acc: 0.7697 - val_loss: 0.5869 - val_acc: 0.6429\n",
      "Epoch 388/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5392 - acc: 0.770 - 0s - loss: 0.5245 - acc: 0.7576 - val_loss: 0.5878 - val_acc: 0.6429\n",
      "Epoch 389/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5241 - acc: 0.7576 - val_loss: 0.5868 - val_acc: 0.6429\n",
      "Epoch 390/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5238 - acc: 0.7576 - val_loss: 0.5866 - val_acc: 0.6429\n",
      "Epoch 391/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5237 - acc: 0.7576 - val_loss: 0.5873 - val_acc: 0.6429\n",
      "Epoch 392/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5176 - acc: 0.760 - 0s - loss: 0.5233 - acc: 0.7576 - val_loss: 0.5866 - val_acc: 0.6429\n",
      "Epoch 393/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5230 - acc: 0.7576 - val_loss: 0.5862 - val_acc: 0.6429\n",
      "Epoch 394/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5231 - acc: 0.7576 - val_loss: 0.5879 - val_acc: 0.6429\n",
      "Epoch 395/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5227 - acc: 0.7576 - val_loss: 0.5851 - val_acc: 0.6429\n",
      "Epoch 396/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5223 - acc: 0.7576 - val_loss: 0.5860 - val_acc: 0.6429\n",
      "Epoch 397/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5220 - acc: 0.7576 - val_loss: 0.5838 - val_acc: 0.6429\n",
      "Epoch 398/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5215 - acc: 0.7576 - val_loss: 0.5832 - val_acc: 0.6429\n",
      "Epoch 399/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5213 - acc: 0.7697 - val_loss: 0.5840 - val_acc: 0.6429\n",
      "Epoch 400/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5211 - acc: 0.7576 - val_loss: 0.5825 - val_acc: 0.6429\n",
      "Epoch 401/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5207 - acc: 0.7697 - val_loss: 0.5830 - val_acc: 0.6429\n",
      "Epoch 402/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5206 - acc: 0.7576 - val_loss: 0.5814 - val_acc: 0.6429\n",
      "Epoch 403/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5203 - acc: 0.7697 - val_loss: 0.5828 - val_acc: 0.6429\n",
      "Epoch 404/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5199 - acc: 0.7636 - val_loss: 0.5814 - val_acc: 0.6429\n",
      "Epoch 405/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5195 - acc: 0.7636 - val_loss: 0.5815 - val_acc: 0.6429\n",
      "Epoch 406/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5195 - acc: 0.7636 - val_loss: 0.5826 - val_acc: 0.6429\n",
      "Epoch 407/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5190 - acc: 0.7576 - val_loss: 0.5825 - val_acc: 0.6429\n",
      "Epoch 408/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5189 - acc: 0.7576 - val_loss: 0.5803 - val_acc: 0.6429\n",
      "Epoch 409/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5184 - acc: 0.7636 - val_loss: 0.5798 - val_acc: 0.6429\n",
      "Epoch 410/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5184 - acc: 0.7697 - val_loss: 0.5811 - val_acc: 0.6429\n",
      "Epoch 411/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5179 - acc: 0.7636 - val_loss: 0.5807 - val_acc: 0.6429\n",
      "Epoch 412/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5176 - acc: 0.7636 - val_loss: 0.5793 - val_acc: 0.6429\n",
      "Epoch 413/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5176 - acc: 0.7697 - val_loss: 0.5807 - val_acc: 0.6429\n",
      "Epoch 414/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5173 - acc: 0.7576 - val_loss: 0.5781 - val_acc: 0.6429\n",
      "Epoch 415/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5167 - acc: 0.7697 - val_loss: 0.5783 - val_acc: 0.6429\n",
      "Epoch 416/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5174 - acc: 0.7636 - val_loss: 0.5748 - val_acc: 0.6429\n",
      "Epoch 417/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5171 - acc: 0.7636 - val_loss: 0.5721 - val_acc: 0.6429\n",
      "Epoch 418/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5165 - acc: 0.7697 - val_loss: 0.5708 - val_acc: 0.6429\n",
      "Epoch 419/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5160 - acc: 0.7697 - val_loss: 0.5734 - val_acc: 0.6429\n",
      "Epoch 420/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5156 - acc: 0.7697 - val_loss: 0.5726 - val_acc: 0.6429\n",
      "Epoch 421/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5155 - acc: 0.7697 - val_loss: 0.5712 - val_acc: 0.6429\n",
      "Epoch 422/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5149 - acc: 0.7697 - val_loss: 0.5716 - val_acc: 0.6429\n",
      "Epoch 423/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5146 - acc: 0.7697 - val_loss: 0.5725 - val_acc: 0.6429\n",
      "Epoch 424/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5153 - acc: 0.7636 - val_loss: 0.5696 - val_acc: 0.6429\n",
      "Epoch 425/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5142 - acc: 0.7697 - val_loss: 0.5713 - val_acc: 0.6429\n",
      "Epoch 426/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5139 - acc: 0.7697 - val_loss: 0.5723 - val_acc: 0.6429\n",
      "Epoch 427/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5136 - acc: 0.7697 - val_loss: 0.5734 - val_acc: 0.6429\n",
      "Epoch 428/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5136 - acc: 0.7697 - val_loss: 0.5713 - val_acc: 0.6429\n",
      "Epoch 429/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5131 - acc: 0.7697 - val_loss: 0.5728 - val_acc: 0.6429\n",
      "Epoch 430/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5127 - acc: 0.7697 - val_loss: 0.5723 - val_acc: 0.6429\n",
      "Epoch 431/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5126 - acc: 0.7697 - val_loss: 0.5714 - val_acc: 0.6429\n",
      "Epoch 432/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5124 - acc: 0.7697 - val_loss: 0.5699 - val_acc: 0.6429\n",
      "Epoch 433/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5119 - acc: 0.7697 - val_loss: 0.5710 - val_acc: 0.6429\n",
      "Epoch 434/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5118 - acc: 0.7697 - val_loss: 0.5695 - val_acc: 0.6429\n",
      "Epoch 435/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5114 - acc: 0.7697 - val_loss: 0.5707 - val_acc: 0.6429\n",
      "Epoch 436/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5117 - acc: 0.7697 - val_loss: 0.5680 - val_acc: 0.6429\n",
      "Epoch 437/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5108 - acc: 0.7697 - val_loss: 0.5688 - val_acc: 0.6429\n",
      "Epoch 438/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5108 - acc: 0.7697 - val_loss: 0.5676 - val_acc: 0.6429\n",
      "Epoch 439/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5103 - acc: 0.7697 - val_loss: 0.5677 - val_acc: 0.6429\n",
      "Epoch 440/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5104 - acc: 0.7758 - val_loss: 0.5702 - val_acc: 0.6429\n",
      "Epoch 441/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5097 - acc: 0.7697 - val_loss: 0.5695 - val_acc: 0.6429\n",
      "Epoch 442/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5099 - acc: 0.7697 - val_loss: 0.5672 - val_acc: 0.6429\n",
      "Epoch 443/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5094 - acc: 0.7697 - val_loss: 0.5660 - val_acc: 0.6429\n",
      "Epoch 444/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5090 - acc: 0.7697 - val_loss: 0.5657 - val_acc: 0.6429\n",
      "Epoch 445/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5087 - acc: 0.7697 - val_loss: 0.5653 - val_acc: 0.6429\n",
      "Epoch 446/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5095 - acc: 0.7697 - val_loss: 0.5624 - val_acc: 0.6667\n",
      "Epoch 447/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5083 - acc: 0.7758 - val_loss: 0.5627 - val_acc: 0.6667\n",
      "Epoch 448/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5079 - acc: 0.7758 - val_loss: 0.5638 - val_acc: 0.6667\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.5080 - acc: 0.7697 - val_loss: 0.5623 - val_acc: 0.6667\n",
      "Epoch 450/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5074 - acc: 0.7758 - val_loss: 0.5632 - val_acc: 0.6667\n",
      "Epoch 451/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5071 - acc: 0.7758 - val_loss: 0.5636 - val_acc: 0.6667\n",
      "Epoch 452/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5068 - acc: 0.7758 - val_loss: 0.5640 - val_acc: 0.6429\n",
      "Epoch 453/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5069 - acc: 0.7697 - val_loss: 0.5624 - val_acc: 0.6667\n",
      "Epoch 454/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5074 - acc: 0.7697 - val_loss: 0.5596 - val_acc: 0.6667\n",
      "Epoch 455/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5062 - acc: 0.7758 - val_loss: 0.5613 - val_acc: 0.6667\n",
      "Epoch 456/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5060 - acc: 0.7758 - val_loss: 0.5606 - val_acc: 0.6667\n",
      "Epoch 457/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5057 - acc: 0.7758 - val_loss: 0.5601 - val_acc: 0.6667\n",
      "Epoch 458/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5053 - acc: 0.7758 - val_loss: 0.5603 - val_acc: 0.6667\n",
      "Epoch 459/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5051 - acc: 0.7758 - val_loss: 0.5602 - val_acc: 0.6667\n",
      "Epoch 460/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5047 - acc: 0.7758 - val_loss: 0.5611 - val_acc: 0.6667\n",
      "Epoch 461/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5045 - acc: 0.7758 - val_loss: 0.5621 - val_acc: 0.6429\n",
      "Epoch 462/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5047 - acc: 0.7758 - val_loss: 0.5599 - val_acc: 0.6667\n",
      "Epoch 463/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5040 - acc: 0.7758 - val_loss: 0.5603 - val_acc: 0.6667\n",
      "Epoch 464/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5038 - acc: 0.7758 - val_loss: 0.5619 - val_acc: 0.6429\n",
      "Epoch 465/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5035 - acc: 0.7758 - val_loss: 0.5624 - val_acc: 0.6429\n",
      "Epoch 466/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5037 - acc: 0.7697 - val_loss: 0.5596 - val_acc: 0.6667\n",
      "Epoch 467/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5030 - acc: 0.7758 - val_loss: 0.5605 - val_acc: 0.6667\n",
      "Epoch 468/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5027 - acc: 0.7758 - val_loss: 0.5603 - val_acc: 0.6667\n",
      "Epoch 469/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5036 - acc: 0.7697 - val_loss: 0.5568 - val_acc: 0.6667\n",
      "Epoch 470/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5023 - acc: 0.7758 - val_loss: 0.5590 - val_acc: 0.6667\n",
      "Epoch 471/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5019 - acc: 0.7758 - val_loss: 0.5601 - val_acc: 0.6667\n",
      "Epoch 472/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5016 - acc: 0.7758 - val_loss: 0.5599 - val_acc: 0.6667\n",
      "Epoch 473/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5015 - acc: 0.7758 - val_loss: 0.5585 - val_acc: 0.6667\n",
      "Epoch 474/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5011 - acc: 0.7758 - val_loss: 0.5590 - val_acc: 0.6667\n",
      "Epoch 475/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5008 - acc: 0.7758 - val_loss: 0.5588 - val_acc: 0.6667\n",
      "Epoch 476/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5006 - acc: 0.7758 - val_loss: 0.5586 - val_acc: 0.6667\n",
      "Epoch 477/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5006 - acc: 0.7758 - val_loss: 0.5604 - val_acc: 0.6429\n",
      "Epoch 478/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5002 - acc: 0.7758 - val_loss: 0.5588 - val_acc: 0.6667\n",
      "Epoch 479/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4999 - acc: 0.7758 - val_loss: 0.5575 - val_acc: 0.6667\n",
      "Epoch 480/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4996 - acc: 0.7758 - val_loss: 0.5571 - val_acc: 0.6667\n",
      "Epoch 481/1000\n",
      "165/165 [==============================] - 0s - loss: 0.5000 - acc: 0.7758 - val_loss: 0.5598 - val_acc: 0.6429\n",
      "Epoch 482/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4992 - acc: 0.7758 - val_loss: 0.5606 - val_acc: 0.6429\n",
      "Epoch 483/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4989 - acc: 0.7758 - val_loss: 0.5590 - val_acc: 0.6429\n",
      "Epoch 484/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4995 - acc: 0.7758 - val_loss: 0.5552 - val_acc: 0.6667\n",
      "Epoch 485/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.5078 - acc: 0.760 - 0s - loss: 0.4984 - acc: 0.7758 - val_loss: 0.5567 - val_acc: 0.6667\n",
      "Epoch 486/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4980 - acc: 0.7758 - val_loss: 0.5569 - val_acc: 0.6667\n",
      "Epoch 487/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4978 - acc: 0.7758 - val_loss: 0.5565 - val_acc: 0.6667\n",
      "Epoch 488/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4978 - acc: 0.7758 - val_loss: 0.5582 - val_acc: 0.6429\n",
      "Epoch 489/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4973 - acc: 0.7758 - val_loss: 0.5585 - val_acc: 0.6429\n",
      "Epoch 490/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4972 - acc: 0.7758 - val_loss: 0.5569 - val_acc: 0.6667\n",
      "Epoch 491/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4969 - acc: 0.7758 - val_loss: 0.5580 - val_acc: 0.6429\n",
      "Epoch 492/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4969 - acc: 0.7758 - val_loss: 0.5551 - val_acc: 0.6667\n",
      "Epoch 493/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4963 - acc: 0.7758 - val_loss: 0.5558 - val_acc: 0.6667\n",
      "Epoch 494/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4961 - acc: 0.7758 - val_loss: 0.5546 - val_acc: 0.6667\n",
      "Epoch 495/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4959 - acc: 0.7758 - val_loss: 0.5532 - val_acc: 0.6667\n",
      "Epoch 496/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4956 - acc: 0.7758 - val_loss: 0.5521 - val_acc: 0.6667\n",
      "Epoch 497/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4954 - acc: 0.7758 - val_loss: 0.5510 - val_acc: 0.6667\n",
      "Epoch 498/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4951 - acc: 0.7758 - val_loss: 0.5520 - val_acc: 0.6667\n",
      "Epoch 499/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4948 - acc: 0.7758 - val_loss: 0.5515 - val_acc: 0.6667\n",
      "Epoch 500/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4946 - acc: 0.7758 - val_loss: 0.5510 - val_acc: 0.6667\n",
      "Epoch 501/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4945 - acc: 0.7758 - val_loss: 0.5528 - val_acc: 0.6667\n",
      "Epoch 502/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4940 - acc: 0.7758 - val_loss: 0.5526 - val_acc: 0.6667\n",
      "Epoch 503/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4940 - acc: 0.7758 - val_loss: 0.5506 - val_acc: 0.6667\n",
      "Epoch 504/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4940 - acc: 0.7758 - val_loss: 0.5484 - val_acc: 0.6667\n",
      "Epoch 505/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4936 - acc: 0.7758 - val_loss: 0.5474 - val_acc: 0.6667\n",
      "Epoch 506/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4933 - acc: 0.7758 - val_loss: 0.5495 - val_acc: 0.6667\n",
      "Epoch 507/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4929 - acc: 0.7758 - val_loss: 0.5493 - val_acc: 0.6667\n",
      "Epoch 508/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4935 - acc: 0.7818 - val_loss: 0.5528 - val_acc: 0.6667\n",
      "Epoch 509/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4923 - acc: 0.7758 - val_loss: 0.5519 - val_acc: 0.6667\n",
      "Epoch 510/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4922 - acc: 0.7758 - val_loss: 0.5526 - val_acc: 0.6667\n",
      "Epoch 511/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4923 - acc: 0.7818 - val_loss: 0.5495 - val_acc: 0.6667\n",
      "Epoch 512/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4918 - acc: 0.7758 - val_loss: 0.5511 - val_acc: 0.6667\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4916 - acc: 0.7758 - val_loss: 0.5521 - val_acc: 0.6667\n",
      "Epoch 514/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4919 - acc: 0.7758 - val_loss: 0.5545 - val_acc: 0.6429\n",
      "Epoch 515/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4915 - acc: 0.7758 - val_loss: 0.5556 - val_acc: 0.6429\n",
      "Epoch 516/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4908 - acc: 0.7818 - val_loss: 0.5543 - val_acc: 0.6429\n",
      "Epoch 517/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4905 - acc: 0.7818 - val_loss: 0.5526 - val_acc: 0.6667\n",
      "Epoch 518/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4903 - acc: 0.7818 - val_loss: 0.5504 - val_acc: 0.6667\n",
      "Epoch 519/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4900 - acc: 0.7758 - val_loss: 0.5511 - val_acc: 0.6667\n",
      "Epoch 520/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4897 - acc: 0.7818 - val_loss: 0.5498 - val_acc: 0.6667\n",
      "Epoch 521/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4898 - acc: 0.7758 - val_loss: 0.5473 - val_acc: 0.6667\n",
      "Epoch 522/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4893 - acc: 0.7758 - val_loss: 0.5485 - val_acc: 0.6667\n",
      "Epoch 523/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4890 - acc: 0.7758 - val_loss: 0.5482 - val_acc: 0.6667\n",
      "Epoch 524/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4889 - acc: 0.7758 - val_loss: 0.5493 - val_acc: 0.6667\n",
      "Epoch 525/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4885 - acc: 0.7818 - val_loss: 0.5478 - val_acc: 0.6667\n",
      "Epoch 526/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4883 - acc: 0.7758 - val_loss: 0.5466 - val_acc: 0.6667\n",
      "Epoch 527/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4882 - acc: 0.7818 - val_loss: 0.5478 - val_acc: 0.6667\n",
      "Epoch 528/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4878 - acc: 0.7758 - val_loss: 0.5479 - val_acc: 0.6667\n",
      "Epoch 529/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4881 - acc: 0.7818 - val_loss: 0.5445 - val_acc: 0.6667\n",
      "Epoch 530/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4873 - acc: 0.7758 - val_loss: 0.5442 - val_acc: 0.6667\n",
      "Epoch 531/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4876 - acc: 0.7879 - val_loss: 0.5467 - val_acc: 0.6667\n",
      "Epoch 532/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4868 - acc: 0.7758 - val_loss: 0.5457 - val_acc: 0.6667\n",
      "Epoch 533/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4869 - acc: 0.7818 - val_loss: 0.5474 - val_acc: 0.6667\n",
      "Epoch 534/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4865 - acc: 0.7818 - val_loss: 0.5477 - val_acc: 0.6667\n",
      "Epoch 535/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4862 - acc: 0.7818 - val_loss: 0.5472 - val_acc: 0.6667\n",
      "Epoch 536/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4862 - acc: 0.7818 - val_loss: 0.5443 - val_acc: 0.6667\n",
      "Epoch 537/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4857 - acc: 0.7758 - val_loss: 0.5445 - val_acc: 0.6667\n",
      "Epoch 538/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4856 - acc: 0.7758 - val_loss: 0.5455 - val_acc: 0.6667\n",
      "Epoch 539/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4852 - acc: 0.7818 - val_loss: 0.5442 - val_acc: 0.6667\n",
      "Epoch 540/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4852 - acc: 0.7758 - val_loss: 0.5453 - val_acc: 0.6667\n",
      "Epoch 541/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4848 - acc: 0.7818 - val_loss: 0.5449 - val_acc: 0.6667\n",
      "Epoch 542/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4847 - acc: 0.7818 - val_loss: 0.5426 - val_acc: 0.6667\n",
      "Epoch 543/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4851 - acc: 0.7879 - val_loss: 0.5456 - val_acc: 0.6667\n",
      "Epoch 544/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4843 - acc: 0.7879 - val_loss: 0.5459 - val_acc: 0.6667\n",
      "Epoch 545/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4839 - acc: 0.7818 - val_loss: 0.5439 - val_acc: 0.6667\n",
      "Epoch 546/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4838 - acc: 0.7818 - val_loss: 0.5412 - val_acc: 0.6667\n",
      "Epoch 547/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4834 - acc: 0.7879 - val_loss: 0.5405 - val_acc: 0.6667\n",
      "Epoch 548/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4831 - acc: 0.7879 - val_loss: 0.5411 - val_acc: 0.6667\n",
      "Epoch 549/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4829 - acc: 0.7879 - val_loss: 0.5404 - val_acc: 0.6667\n",
      "Epoch 550/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4829 - acc: 0.7879 - val_loss: 0.5414 - val_acc: 0.6667\n",
      "Epoch 551/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4825 - acc: 0.7879 - val_loss: 0.5421 - val_acc: 0.6667\n",
      "Epoch 552/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4824 - acc: 0.7939 - val_loss: 0.5427 - val_acc: 0.6667\n",
      "Epoch 553/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4820 - acc: 0.7879 - val_loss: 0.5411 - val_acc: 0.6667\n",
      "Epoch 554/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4826 - acc: 0.7939 - val_loss: 0.5438 - val_acc: 0.6667\n",
      "Epoch 555/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4816 - acc: 0.7879 - val_loss: 0.5424 - val_acc: 0.6667\n",
      "Epoch 556/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4814 - acc: 0.7879 - val_loss: 0.5402 - val_acc: 0.6667\n",
      "Epoch 557/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4814 - acc: 0.8000 - val_loss: 0.5416 - val_acc: 0.6667\n",
      "Epoch 558/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4809 - acc: 0.7939 - val_loss: 0.5402 - val_acc: 0.6667\n",
      "Epoch 559/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4807 - acc: 0.8000 - val_loss: 0.5409 - val_acc: 0.6667\n",
      "Epoch 560/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4804 - acc: 0.7939 - val_loss: 0.5398 - val_acc: 0.6667\n",
      "Epoch 561/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4806 - acc: 0.7939 - val_loss: 0.5414 - val_acc: 0.6667\n",
      "Epoch 562/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4801 - acc: 0.7879 - val_loss: 0.5386 - val_acc: 0.6667\n",
      "Epoch 563/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4800 - acc: 0.7939 - val_loss: 0.5400 - val_acc: 0.6667\n",
      "Epoch 564/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4795 - acc: 0.8000 - val_loss: 0.5384 - val_acc: 0.6667\n",
      "Epoch 565/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4798 - acc: 0.8000 - val_loss: 0.5351 - val_acc: 0.6667\n",
      "Epoch 566/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4791 - acc: 0.7939 - val_loss: 0.5356 - val_acc: 0.6667\n",
      "Epoch 567/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4791 - acc: 0.7939 - val_loss: 0.5374 - val_acc: 0.6667\n",
      "Epoch 568/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4786 - acc: 0.8000 - val_loss: 0.5362 - val_acc: 0.6667\n",
      "Epoch 569/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4785 - acc: 0.8000 - val_loss: 0.5370 - val_acc: 0.6667\n",
      "Epoch 570/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4788 - acc: 0.8000 - val_loss: 0.5337 - val_acc: 0.6667\n",
      "Epoch 571/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4782 - acc: 0.8000 - val_loss: 0.5320 - val_acc: 0.6667\n",
      "Epoch 572/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4777 - acc: 0.8000 - val_loss: 0.5321 - val_acc: 0.6667\n",
      "Epoch 573/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4776 - acc: 0.8000 - val_loss: 0.5313 - val_acc: 0.6667\n",
      "Epoch 574/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4773 - acc: 0.8000 - val_loss: 0.5318 - val_acc: 0.6667\n",
      "Epoch 575/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4771 - acc: 0.8061 - val_loss: 0.5314 - val_acc: 0.6667\n",
      "Epoch 576/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4770 - acc: 0.8061 - val_loss: 0.5305 - val_acc: 0.6667\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4766 - acc: 0.8000 - val_loss: 0.5313 - val_acc: 0.6667\n",
      "Epoch 578/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4768 - acc: 0.8000 - val_loss: 0.5340 - val_acc: 0.6667\n",
      "Epoch 579/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4765 - acc: 0.8061 - val_loss: 0.5357 - val_acc: 0.6667\n",
      "Epoch 580/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4760 - acc: 0.8000 - val_loss: 0.5346 - val_acc: 0.6667\n",
      "Epoch 581/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4758 - acc: 0.8000 - val_loss: 0.5343 - val_acc: 0.6667\n",
      "Epoch 582/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4757 - acc: 0.8000 - val_loss: 0.5351 - val_acc: 0.6667\n",
      "Epoch 583/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4753 - acc: 0.8000 - val_loss: 0.5337 - val_acc: 0.6667\n",
      "Epoch 584/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4751 - acc: 0.8061 - val_loss: 0.5336 - val_acc: 0.6667\n",
      "Epoch 585/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4750 - acc: 0.8061 - val_loss: 0.5344 - val_acc: 0.6667\n",
      "Epoch 586/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4749 - acc: 0.8061 - val_loss: 0.5353 - val_acc: 0.6667\n",
      "Epoch 587/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4745 - acc: 0.8000 - val_loss: 0.5348 - val_acc: 0.6667\n",
      "Epoch 588/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4746 - acc: 0.8000 - val_loss: 0.5360 - val_acc: 0.6667\n",
      "Epoch 589/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4766 - acc: 0.810 - 0s - loss: 0.4741 - acc: 0.8000 - val_loss: 0.5353 - val_acc: 0.6667\n",
      "Epoch 590/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4739 - acc: 0.8000 - val_loss: 0.5356 - val_acc: 0.6667\n",
      "Epoch 591/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4740 - acc: 0.8000 - val_loss: 0.5315 - val_acc: 0.6667\n",
      "Epoch 592/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4733 - acc: 0.8061 - val_loss: 0.5316 - val_acc: 0.6667\n",
      "Epoch 593/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4733 - acc: 0.8061 - val_loss: 0.5292 - val_acc: 0.6667\n",
      "Epoch 594/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4730 - acc: 0.8061 - val_loss: 0.5283 - val_acc: 0.6429\n",
      "Epoch 595/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4733 - acc: 0.8000 - val_loss: 0.5315 - val_acc: 0.6667\n",
      "Epoch 596/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4729 - acc: 0.8061 - val_loss: 0.5330 - val_acc: 0.6667\n",
      "Epoch 597/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4725 - acc: 0.8000 - val_loss: 0.5334 - val_acc: 0.6667\n",
      "Epoch 598/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4724 - acc: 0.8000 - val_loss: 0.5298 - val_acc: 0.6667\n",
      "Epoch 599/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4720 - acc: 0.8061 - val_loss: 0.5278 - val_acc: 0.6667\n",
      "Epoch 600/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4716 - acc: 0.8061 - val_loss: 0.5273 - val_acc: 0.6667\n",
      "Epoch 601/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4714 - acc: 0.8061 - val_loss: 0.5274 - val_acc: 0.6667\n",
      "Epoch 602/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4712 - acc: 0.8061 - val_loss: 0.5278 - val_acc: 0.6667\n",
      "Epoch 603/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4714 - acc: 0.8000 - val_loss: 0.5251 - val_acc: 0.6429\n",
      "Epoch 604/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4708 - acc: 0.8000 - val_loss: 0.5255 - val_acc: 0.6429\n",
      "Epoch 605/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4709 - acc: 0.8000 - val_loss: 0.5276 - val_acc: 0.6667\n",
      "Epoch 606/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4716 - acc: 0.8061 - val_loss: 0.5231 - val_acc: 0.6429\n",
      "Epoch 607/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4703 - acc: 0.8000 - val_loss: 0.5228 - val_acc: 0.6429\n",
      "Epoch 608/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4700 - acc: 0.8000 - val_loss: 0.5236 - val_acc: 0.6429\n",
      "Epoch 609/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4700 - acc: 0.8061 - val_loss: 0.5225 - val_acc: 0.6429\n",
      "Epoch 610/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4701 - acc: 0.8061 - val_loss: 0.5206 - val_acc: 0.6429\n",
      "Epoch 611/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4694 - acc: 0.8000 - val_loss: 0.5215 - val_acc: 0.6429\n",
      "Epoch 612/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4692 - acc: 0.8061 - val_loss: 0.5222 - val_acc: 0.6429\n",
      "Epoch 613/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4689 - acc: 0.8061 - val_loss: 0.5231 - val_acc: 0.6429\n",
      "Epoch 614/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4687 - acc: 0.8000 - val_loss: 0.5232 - val_acc: 0.6429\n",
      "Epoch 615/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4686 - acc: 0.8000 - val_loss: 0.5220 - val_acc: 0.6429\n",
      "Epoch 616/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4683 - acc: 0.8000 - val_loss: 0.5231 - val_acc: 0.6429\n",
      "Epoch 617/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4683 - acc: 0.8000 - val_loss: 0.5251 - val_acc: 0.6667\n",
      "Epoch 618/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4678 - acc: 0.8061 - val_loss: 0.5243 - val_acc: 0.6429\n",
      "Epoch 619/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4677 - acc: 0.8061 - val_loss: 0.5229 - val_acc: 0.6429\n",
      "Epoch 620/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4675 - acc: 0.8000 - val_loss: 0.5238 - val_acc: 0.6429\n",
      "Epoch 621/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4672 - acc: 0.8061 - val_loss: 0.5232 - val_acc: 0.6429\n",
      "Epoch 622/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4670 - acc: 0.8061 - val_loss: 0.5227 - val_acc: 0.6429\n",
      "Epoch 623/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4670 - acc: 0.8061 - val_loss: 0.5213 - val_acc: 0.6429\n",
      "Epoch 624/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4670 - acc: 0.8000 - val_loss: 0.5238 - val_acc: 0.6429\n",
      "Epoch 625/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4664 - acc: 0.8061 - val_loss: 0.5224 - val_acc: 0.6429\n",
      "Epoch 626/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4672 - acc: 0.8000 - val_loss: 0.5259 - val_acc: 0.6667\n",
      "Epoch 627/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4661 - acc: 0.8061 - val_loss: 0.5252 - val_acc: 0.6667\n",
      "Epoch 628/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4658 - acc: 0.8061 - val_loss: 0.5239 - val_acc: 0.6667\n",
      "Epoch 629/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4656 - acc: 0.8061 - val_loss: 0.5234 - val_acc: 0.6667\n",
      "Epoch 630/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4655 - acc: 0.8000 - val_loss: 0.5241 - val_acc: 0.6667\n",
      "Epoch 631/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4653 - acc: 0.8061 - val_loss: 0.5220 - val_acc: 0.6429\n",
      "Epoch 632/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4650 - acc: 0.8061 - val_loss: 0.5212 - val_acc: 0.6429\n",
      "Epoch 633/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4648 - acc: 0.8061 - val_loss: 0.5214 - val_acc: 0.6429\n",
      "Epoch 634/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4646 - acc: 0.8061 - val_loss: 0.5207 - val_acc: 0.6429\n",
      "Epoch 635/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4645 - acc: 0.8000 - val_loss: 0.5219 - val_acc: 0.6429\n",
      "Epoch 636/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4645 - acc: 0.8061 - val_loss: 0.5235 - val_acc: 0.6667\n",
      "Epoch 637/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4640 - acc: 0.8061 - val_loss: 0.5233 - val_acc: 0.6667\n",
      "Epoch 638/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4639 - acc: 0.8061 - val_loss: 0.5213 - val_acc: 0.6429\n",
      "Epoch 639/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4639 - acc: 0.8061 - val_loss: 0.5186 - val_acc: 0.6429\n",
      "Epoch 640/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4634 - acc: 0.8061 - val_loss: 0.5182 - val_acc: 0.6429\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4632 - acc: 0.8061 - val_loss: 0.5191 - val_acc: 0.6429\n",
      "Epoch 642/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4630 - acc: 0.8061 - val_loss: 0.5198 - val_acc: 0.6429\n",
      "Epoch 643/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4628 - acc: 0.8121 - val_loss: 0.5184 - val_acc: 0.6429\n",
      "Epoch 644/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4632 - acc: 0.8061 - val_loss: 0.5154 - val_acc: 0.6429\n",
      "Epoch 645/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4625 - acc: 0.8061 - val_loss: 0.5148 - val_acc: 0.6429\n",
      "Epoch 646/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4622 - acc: 0.8000 - val_loss: 0.5163 - val_acc: 0.6429\n",
      "Epoch 647/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4620 - acc: 0.8000 - val_loss: 0.5166 - val_acc: 0.6429\n",
      "Epoch 648/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4619 - acc: 0.8061 - val_loss: 0.5161 - val_acc: 0.6429\n",
      "Epoch 649/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4619 - acc: 0.8000 - val_loss: 0.5141 - val_acc: 0.6429\n",
      "Epoch 650/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4614 - acc: 0.8061 - val_loss: 0.5143 - val_acc: 0.6429\n",
      "Epoch 651/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4615 - acc: 0.8061 - val_loss: 0.5165 - val_acc: 0.6429\n",
      "Epoch 652/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4610 - acc: 0.8000 - val_loss: 0.5170 - val_acc: 0.6429\n",
      "Epoch 653/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4608 - acc: 0.8061 - val_loss: 0.5170 - val_acc: 0.6429\n",
      "Epoch 654/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4608 - acc: 0.8000 - val_loss: 0.5177 - val_acc: 0.6429\n",
      "Epoch 655/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4605 - acc: 0.8121 - val_loss: 0.5179 - val_acc: 0.6429\n",
      "Epoch 656/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4605 - acc: 0.8061 - val_loss: 0.5159 - val_acc: 0.6429\n",
      "Epoch 657/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4602 - acc: 0.8061 - val_loss: 0.5142 - val_acc: 0.6429\n",
      "Epoch 658/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4600 - acc: 0.8000 - val_loss: 0.5131 - val_acc: 0.6429\n",
      "Epoch 659/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4597 - acc: 0.8061 - val_loss: 0.5141 - val_acc: 0.6429\n",
      "Epoch 660/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4597 - acc: 0.8121 - val_loss: 0.5123 - val_acc: 0.6429\n",
      "Epoch 661/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4595 - acc: 0.8061 - val_loss: 0.5108 - val_acc: 0.6429\n",
      "Epoch 662/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4591 - acc: 0.8061 - val_loss: 0.5110 - val_acc: 0.6429\n",
      "Epoch 663/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4589 - acc: 0.8121 - val_loss: 0.5119 - val_acc: 0.6429\n",
      "Epoch 664/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4588 - acc: 0.8061 - val_loss: 0.5137 - val_acc: 0.6429\n",
      "Epoch 665/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4584 - acc: 0.8000 - val_loss: 0.5137 - val_acc: 0.6429\n",
      "Epoch 666/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4584 - acc: 0.8061 - val_loss: 0.5149 - val_acc: 0.6429\n",
      "Epoch 667/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4581 - acc: 0.8000 - val_loss: 0.5135 - val_acc: 0.6429\n",
      "Epoch 668/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4579 - acc: 0.8061 - val_loss: 0.5131 - val_acc: 0.6429\n",
      "Epoch 669/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4577 - acc: 0.8061 - val_loss: 0.5141 - val_acc: 0.6429\n",
      "Epoch 670/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4584 - acc: 0.8061 - val_loss: 0.5102 - val_acc: 0.6429\n",
      "Epoch 671/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4596 - acc: 0.810 - 0s - loss: 0.4574 - acc: 0.8121 - val_loss: 0.5104 - val_acc: 0.6429\n",
      "Epoch 672/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4572 - acc: 0.8121 - val_loss: 0.5100 - val_acc: 0.6429\n",
      "Epoch 673/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4571 - acc: 0.8121 - val_loss: 0.5121 - val_acc: 0.6429\n",
      "Epoch 674/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4567 - acc: 0.8121 - val_loss: 0.5126 - val_acc: 0.6429\n",
      "Epoch 675/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4566 - acc: 0.8061 - val_loss: 0.5124 - val_acc: 0.6429\n",
      "Epoch 676/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4567 - acc: 0.8121 - val_loss: 0.5143 - val_acc: 0.6429\n",
      "Epoch 677/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4563 - acc: 0.8061 - val_loss: 0.5122 - val_acc: 0.6429\n",
      "Epoch 678/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4560 - acc: 0.8121 - val_loss: 0.5127 - val_acc: 0.6429\n",
      "Epoch 679/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4559 - acc: 0.8000 - val_loss: 0.5110 - val_acc: 0.6429\n",
      "Epoch 680/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4556 - acc: 0.8121 - val_loss: 0.5103 - val_acc: 0.6429\n",
      "Epoch 681/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4555 - acc: 0.8121 - val_loss: 0.5088 - val_acc: 0.6429\n",
      "Epoch 682/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4557 - acc: 0.8061 - val_loss: 0.5067 - val_acc: 0.6667\n",
      "Epoch 683/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4550 - acc: 0.8121 - val_loss: 0.5072 - val_acc: 0.6429\n",
      "Epoch 684/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4548 - acc: 0.8121 - val_loss: 0.5078 - val_acc: 0.6429\n",
      "Epoch 685/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4551 - acc: 0.8121 - val_loss: 0.5058 - val_acc: 0.6667\n",
      "Epoch 686/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4545 - acc: 0.8121 - val_loss: 0.5077 - val_acc: 0.6429\n",
      "Epoch 687/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4543 - acc: 0.8121 - val_loss: 0.5071 - val_acc: 0.6667\n",
      "Epoch 688/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4541 - acc: 0.8121 - val_loss: 0.5083 - val_acc: 0.6429\n",
      "Epoch 689/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4544 - acc: 0.8121 - val_loss: 0.5056 - val_acc: 0.6667\n",
      "Epoch 690/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4548 - acc: 0.8121 - val_loss: 0.5026 - val_acc: 0.6667\n",
      "Epoch 691/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4538 - acc: 0.8121 - val_loss: 0.5026 - val_acc: 0.6667\n",
      "Epoch 692/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4535 - acc: 0.8121 - val_loss: 0.5030 - val_acc: 0.6667\n",
      "Epoch 693/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4532 - acc: 0.8121 - val_loss: 0.5042 - val_acc: 0.6667\n",
      "Epoch 694/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4530 - acc: 0.8121 - val_loss: 0.5052 - val_acc: 0.6667\n",
      "Epoch 695/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4528 - acc: 0.8121 - val_loss: 0.5047 - val_acc: 0.6667\n",
      "Epoch 696/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4526 - acc: 0.8121 - val_loss: 0.5061 - val_acc: 0.6667\n",
      "Epoch 697/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4525 - acc: 0.8121 - val_loss: 0.5081 - val_acc: 0.6429\n",
      "Epoch 698/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4522 - acc: 0.8121 - val_loss: 0.5084 - val_acc: 0.6429\n",
      "Epoch 699/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4519 - acc: 0.8121 - val_loss: 0.5084 - val_acc: 0.6429\n",
      "Epoch 700/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4518 - acc: 0.8121 - val_loss: 0.5070 - val_acc: 0.6667\n",
      "Epoch 701/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4516 - acc: 0.8121 - val_loss: 0.5074 - val_acc: 0.6667\n",
      "Epoch 702/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4514 - acc: 0.8121 - val_loss: 0.5064 - val_acc: 0.6667\n",
      "Epoch 703/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4514 - acc: 0.8121 - val_loss: 0.5049 - val_acc: 0.6667\n",
      "Epoch 704/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4510 - acc: 0.8121 - val_loss: 0.5053 - val_acc: 0.6667\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4511 - acc: 0.8121 - val_loss: 0.5038 - val_acc: 0.6667\n",
      "Epoch 706/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4510 - acc: 0.8121 - val_loss: 0.5020 - val_acc: 0.6667\n",
      "Epoch 707/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4507 - acc: 0.8121 - val_loss: 0.5047 - val_acc: 0.6667\n",
      "Epoch 708/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4502 - acc: 0.8121 - val_loss: 0.5045 - val_acc: 0.6667\n",
      "Epoch 709/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4718 - acc: 0.780 - 0s - loss: 0.4504 - acc: 0.8121 - val_loss: 0.5070 - val_acc: 0.6667\n",
      "Epoch 710/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4499 - acc: 0.8121 - val_loss: 0.5057 - val_acc: 0.6667\n",
      "Epoch 711/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4498 - acc: 0.8121 - val_loss: 0.5042 - val_acc: 0.6667\n",
      "Epoch 712/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4562 - acc: 0.790 - 0s - loss: 0.4495 - acc: 0.8121 - val_loss: 0.5037 - val_acc: 0.6667\n",
      "Epoch 713/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4493 - acc: 0.8121 - val_loss: 0.5032 - val_acc: 0.6667\n",
      "Epoch 714/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4500 - acc: 0.8121 - val_loss: 0.5000 - val_acc: 0.6905\n",
      "Epoch 715/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4491 - acc: 0.8121 - val_loss: 0.4999 - val_acc: 0.6905\n",
      "Epoch 716/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4492 - acc: 0.8121 - val_loss: 0.4985 - val_acc: 0.6905\n",
      "Epoch 717/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4500 - acc: 0.8121 - val_loss: 0.4955 - val_acc: 0.7143\n",
      "Epoch 718/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4488 - acc: 0.8121 - val_loss: 0.4961 - val_acc: 0.7143\n",
      "Epoch 719/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4484 - acc: 0.8121 - val_loss: 0.4980 - val_acc: 0.7143\n",
      "Epoch 720/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4483 - acc: 0.8121 - val_loss: 0.5010 - val_acc: 0.6905\n",
      "Epoch 721/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4482 - acc: 0.8121 - val_loss: 0.4993 - val_acc: 0.6905\n",
      "Epoch 722/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4478 - acc: 0.8121 - val_loss: 0.5012 - val_acc: 0.6905\n",
      "Epoch 723/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4481 - acc: 0.8121 - val_loss: 0.5043 - val_acc: 0.6667\n",
      "Epoch 724/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4474 - acc: 0.8121 - val_loss: 0.5033 - val_acc: 0.6667\n",
      "Epoch 725/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4486 - acc: 0.8121 - val_loss: 0.4984 - val_acc: 0.7143\n",
      "Epoch 726/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4476 - acc: 0.8121 - val_loss: 0.5024 - val_acc: 0.6667\n",
      "Epoch 727/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4470 - acc: 0.8121 - val_loss: 0.5001 - val_acc: 0.6905\n",
      "Epoch 728/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4466 - acc: 0.8121 - val_loss: 0.5007 - val_acc: 0.6905\n",
      "Epoch 729/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4467 - acc: 0.8121 - val_loss: 0.4989 - val_acc: 0.6905\n",
      "Epoch 730/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4463 - acc: 0.8121 - val_loss: 0.4990 - val_acc: 0.6905\n",
      "Epoch 731/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4465 - acc: 0.8121 - val_loss: 0.4972 - val_acc: 0.7143\n",
      "Epoch 732/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4461 - acc: 0.8121 - val_loss: 0.4963 - val_acc: 0.7143\n",
      "Epoch 733/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4458 - acc: 0.8121 - val_loss: 0.4971 - val_acc: 0.7143\n",
      "Epoch 734/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4456 - acc: 0.8121 - val_loss: 0.4977 - val_acc: 0.7143\n",
      "Epoch 735/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4457 - acc: 0.8121 - val_loss: 0.4961 - val_acc: 0.7143\n",
      "Epoch 736/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4452 - acc: 0.8121 - val_loss: 0.4979 - val_acc: 0.7143\n",
      "Epoch 737/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4450 - acc: 0.8121 - val_loss: 0.4981 - val_acc: 0.7143\n",
      "Epoch 738/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4450 - acc: 0.8121 - val_loss: 0.4970 - val_acc: 0.7143\n",
      "Epoch 739/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4308 - acc: 0.840 - 0s - loss: 0.4446 - acc: 0.8121 - val_loss: 0.4971 - val_acc: 0.7143\n",
      "Epoch 740/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4444 - acc: 0.8121 - val_loss: 0.4974 - val_acc: 0.7143\n",
      "Epoch 741/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4446 - acc: 0.8121 - val_loss: 0.5001 - val_acc: 0.6905\n",
      "Epoch 742/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4444 - acc: 0.8121 - val_loss: 0.5018 - val_acc: 0.6667\n",
      "Epoch 743/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4440 - acc: 0.8121 - val_loss: 0.5017 - val_acc: 0.6667\n",
      "Epoch 744/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4438 - acc: 0.8121 - val_loss: 0.5000 - val_acc: 0.6905\n",
      "Epoch 745/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4438 - acc: 0.8121 - val_loss: 0.5013 - val_acc: 0.6905\n",
      "Epoch 746/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4434 - acc: 0.8121 - val_loss: 0.5009 - val_acc: 0.6905\n",
      "Epoch 747/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4433 - acc: 0.8121 - val_loss: 0.4997 - val_acc: 0.6905\n",
      "Epoch 748/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4432 - acc: 0.8121 - val_loss: 0.4979 - val_acc: 0.7143\n",
      "Epoch 749/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4408 - acc: 0.820 - 0s - loss: 0.4429 - acc: 0.8121 - val_loss: 0.4979 - val_acc: 0.7143\n",
      "Epoch 750/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4438 - acc: 0.8121 - val_loss: 0.4938 - val_acc: 0.7143\n",
      "Epoch 751/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4426 - acc: 0.8182 - val_loss: 0.4941 - val_acc: 0.7143\n",
      "Epoch 752/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4424 - acc: 0.8121 - val_loss: 0.4946 - val_acc: 0.7143\n",
      "Epoch 753/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4424 - acc: 0.8121 - val_loss: 0.4958 - val_acc: 0.7143\n",
      "Epoch 754/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4422 - acc: 0.8121 - val_loss: 0.4948 - val_acc: 0.7143\n",
      "Epoch 755/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4420 - acc: 0.8182 - val_loss: 0.4972 - val_acc: 0.7143\n",
      "Epoch 756/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4419 - acc: 0.8121 - val_loss: 0.4990 - val_acc: 0.7143\n",
      "Epoch 757/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4415 - acc: 0.8121 - val_loss: 0.4992 - val_acc: 0.7143\n",
      "Epoch 758/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4414 - acc: 0.8121 - val_loss: 0.4985 - val_acc: 0.7143\n",
      "Epoch 759/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4425 - acc: 0.8182 - val_loss: 0.5024 - val_acc: 0.6667\n",
      "Epoch 760/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4411 - acc: 0.8182 - val_loss: 0.4994 - val_acc: 0.7143\n",
      "Epoch 761/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4419 - acc: 0.8182 - val_loss: 0.4946 - val_acc: 0.7143\n",
      "Epoch 762/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4406 - acc: 0.8182 - val_loss: 0.4945 - val_acc: 0.7143\n",
      "Epoch 763/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4407 - acc: 0.8182 - val_loss: 0.4969 - val_acc: 0.7143\n",
      "Epoch 764/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4403 - acc: 0.8121 - val_loss: 0.4961 - val_acc: 0.7143\n",
      "Epoch 765/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4403 - acc: 0.8121 - val_loss: 0.4940 - val_acc: 0.7143\n",
      "Epoch 766/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4400 - acc: 0.8121 - val_loss: 0.4931 - val_acc: 0.7143\n",
      "Epoch 767/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4402 - acc: 0.8182 - val_loss: 0.4962 - val_acc: 0.7143\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4396 - acc: 0.8121 - val_loss: 0.4951 - val_acc: 0.7143\n",
      "Epoch 769/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4395 - acc: 0.8121 - val_loss: 0.4962 - val_acc: 0.7143\n",
      "Epoch 770/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4397 - acc: 0.8182 - val_loss: 0.4980 - val_acc: 0.7143\n",
      "Epoch 771/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4392 - acc: 0.8121 - val_loss: 0.4986 - val_acc: 0.7143\n",
      "Epoch 772/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4391 - acc: 0.8121 - val_loss: 0.4991 - val_acc: 0.7143\n",
      "Epoch 773/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4388 - acc: 0.8121 - val_loss: 0.4976 - val_acc: 0.7143\n",
      "Epoch 774/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4388 - acc: 0.8121 - val_loss: 0.4983 - val_acc: 0.7143\n",
      "Epoch 775/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4385 - acc: 0.8121 - val_loss: 0.4979 - val_acc: 0.7143\n",
      "Epoch 776/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4382 - acc: 0.8121 - val_loss: 0.4964 - val_acc: 0.7143\n",
      "Epoch 777/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4385 - acc: 0.8121 - val_loss: 0.4930 - val_acc: 0.7143\n",
      "Epoch 778/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4379 - acc: 0.8182 - val_loss: 0.4928 - val_acc: 0.7143\n",
      "Epoch 779/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4379 - acc: 0.8182 - val_loss: 0.4942 - val_acc: 0.7143\n",
      "Epoch 780/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4376 - acc: 0.8182 - val_loss: 0.4940 - val_acc: 0.7143\n",
      "Epoch 781/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4374 - acc: 0.8182 - val_loss: 0.4937 - val_acc: 0.7143\n",
      "Epoch 782/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4373 - acc: 0.8182 - val_loss: 0.4940 - val_acc: 0.7143\n",
      "Epoch 783/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4370 - acc: 0.8182 - val_loss: 0.4933 - val_acc: 0.7143\n",
      "Epoch 784/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4272 - acc: 0.830 - 0s - loss: 0.4370 - acc: 0.8182 - val_loss: 0.4944 - val_acc: 0.7143\n",
      "Epoch 785/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4256 - acc: 0.780 - 0s - loss: 0.4367 - acc: 0.8121 - val_loss: 0.4940 - val_acc: 0.7143\n",
      "Epoch 786/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4379 - acc: 0.8182 - val_loss: 0.4982 - val_acc: 0.7143\n",
      "Epoch 787/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4365 - acc: 0.8121 - val_loss: 0.4957 - val_acc: 0.7143\n",
      "Epoch 788/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4370 - acc: 0.8121 - val_loss: 0.4913 - val_acc: 0.7143\n",
      "Epoch 789/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4362 - acc: 0.8182 - val_loss: 0.4927 - val_acc: 0.7143\n",
      "Epoch 790/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4359 - acc: 0.8182 - val_loss: 0.4918 - val_acc: 0.7143\n",
      "Epoch 791/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4357 - acc: 0.8182 - val_loss: 0.4922 - val_acc: 0.7143\n",
      "Epoch 792/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4357 - acc: 0.8182 - val_loss: 0.4932 - val_acc: 0.7143\n",
      "Epoch 793/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4354 - acc: 0.8182 - val_loss: 0.4933 - val_acc: 0.7143\n",
      "Epoch 794/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4353 - acc: 0.8182 - val_loss: 0.4916 - val_acc: 0.7143\n",
      "Epoch 795/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4351 - acc: 0.8182 - val_loss: 0.4918 - val_acc: 0.7143\n",
      "Epoch 796/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4352 - acc: 0.8182 - val_loss: 0.4937 - val_acc: 0.7143\n",
      "Epoch 797/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4547 - acc: 0.790 - 0s - loss: 0.4348 - acc: 0.8182 - val_loss: 0.4931 - val_acc: 0.7143\n",
      "Epoch 798/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4348 - acc: 0.8182 - val_loss: 0.4904 - val_acc: 0.7143\n",
      "Epoch 799/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4350 - acc: 0.8182 - val_loss: 0.4872 - val_acc: 0.7143\n",
      "Epoch 800/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4344 - acc: 0.8182 - val_loss: 0.4866 - val_acc: 0.7143\n",
      "Epoch 801/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4341 - acc: 0.8182 - val_loss: 0.4876 - val_acc: 0.7143\n",
      "Epoch 802/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4340 - acc: 0.8182 - val_loss: 0.4873 - val_acc: 0.7143\n",
      "Epoch 803/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4342 - acc: 0.8182 - val_loss: 0.4906 - val_acc: 0.7143\n",
      "Epoch 804/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4336 - acc: 0.8182 - val_loss: 0.4895 - val_acc: 0.7143\n",
      "Epoch 805/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4338 - acc: 0.8182 - val_loss: 0.4918 - val_acc: 0.7143\n",
      "Epoch 806/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4333 - acc: 0.8182 - val_loss: 0.4914 - val_acc: 0.7143\n",
      "Epoch 807/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4331 - acc: 0.8182 - val_loss: 0.4903 - val_acc: 0.7143\n",
      "Epoch 808/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4356 - acc: 0.8182 - val_loss: 0.4833 - val_acc: 0.7143\n",
      "Epoch 809/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4332 - acc: 0.8182 - val_loss: 0.4826 - val_acc: 0.7143\n",
      "Epoch 810/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4327 - acc: 0.8182 - val_loss: 0.4836 - val_acc: 0.7143\n",
      "Epoch 811/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4332 - acc: 0.8182 - val_loss: 0.4881 - val_acc: 0.7143\n",
      "Epoch 812/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4324 - acc: 0.8182 - val_loss: 0.4870 - val_acc: 0.7143\n",
      "Epoch 813/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4322 - acc: 0.8182 - val_loss: 0.4860 - val_acc: 0.7143\n",
      "Epoch 814/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4322 - acc: 0.8182 - val_loss: 0.4884 - val_acc: 0.7143\n",
      "Epoch 815/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4325 - acc: 0.8182 - val_loss: 0.4915 - val_acc: 0.7143\n",
      "Epoch 816/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4317 - acc: 0.8182 - val_loss: 0.4906 - val_acc: 0.7143\n",
      "Epoch 817/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4317 - acc: 0.8182 - val_loss: 0.4883 - val_acc: 0.7143\n",
      "Epoch 818/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4313 - acc: 0.8182 - val_loss: 0.4876 - val_acc: 0.7143\n",
      "Epoch 819/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4313 - acc: 0.8182 - val_loss: 0.4888 - val_acc: 0.7143\n",
      "Epoch 820/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4310 - acc: 0.8182 - val_loss: 0.4876 - val_acc: 0.7143\n",
      "Epoch 821/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4310 - acc: 0.8182 - val_loss: 0.4891 - val_acc: 0.7143\n",
      "Epoch 822/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4307 - acc: 0.8182 - val_loss: 0.4887 - val_acc: 0.7143\n",
      "Epoch 823/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4721 - acc: 0.760 - 0s - loss: 0.4327 - acc: 0.8182 - val_loss: 0.4940 - val_acc: 0.7143\n",
      "Epoch 824/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4307 - acc: 0.8182 - val_loss: 0.4938 - val_acc: 0.7143\n",
      "Epoch 825/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4304 - acc: 0.8242 - val_loss: 0.4917 - val_acc: 0.7143\n",
      "Epoch 826/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4302 - acc: 0.8182 - val_loss: 0.4910 - val_acc: 0.7143\n",
      "Epoch 827/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4300 - acc: 0.8182 - val_loss: 0.4890 - val_acc: 0.7143\n",
      "Epoch 828/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4298 - acc: 0.8182 - val_loss: 0.4895 - val_acc: 0.7143\n",
      "Epoch 829/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4299 - acc: 0.8182 - val_loss: 0.4905 - val_acc: 0.7143\n",
      "Epoch 830/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4298 - acc: 0.8182 - val_loss: 0.4913 - val_acc: 0.7143\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4299 - acc: 0.8121 - val_loss: 0.4864 - val_acc: 0.7143\n",
      "Epoch 832/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4293 - acc: 0.8182 - val_loss: 0.4842 - val_acc: 0.7143\n",
      "Epoch 833/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4290 - acc: 0.8182 - val_loss: 0.4853 - val_acc: 0.7143\n",
      "Epoch 834/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4300 - acc: 0.8182 - val_loss: 0.4808 - val_acc: 0.7143\n",
      "Epoch 835/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4287 - acc: 0.8182 - val_loss: 0.4809 - val_acc: 0.7143\n",
      "Epoch 836/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4286 - acc: 0.8182 - val_loss: 0.4832 - val_acc: 0.7143\n",
      "Epoch 837/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4283 - acc: 0.8182 - val_loss: 0.4843 - val_acc: 0.7143\n",
      "Epoch 838/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4285 - acc: 0.8182 - val_loss: 0.4822 - val_acc: 0.7143\n",
      "Epoch 839/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4280 - acc: 0.8182 - val_loss: 0.4832 - val_acc: 0.7143\n",
      "Epoch 840/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4282 - acc: 0.8182 - val_loss: 0.4857 - val_acc: 0.7143\n",
      "Epoch 841/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4278 - acc: 0.8182 - val_loss: 0.4840 - val_acc: 0.7143\n",
      "Epoch 842/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4277 - acc: 0.8182 - val_loss: 0.4853 - val_acc: 0.7143\n",
      "Epoch 843/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4276 - acc: 0.8182 - val_loss: 0.4865 - val_acc: 0.7143\n",
      "Epoch 844/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4272 - acc: 0.8182 - val_loss: 0.4861 - val_acc: 0.7143\n",
      "Epoch 845/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4271 - acc: 0.8182 - val_loss: 0.4844 - val_acc: 0.7143\n",
      "Epoch 846/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4195 - acc: 0.820 - 0s - loss: 0.4269 - acc: 0.8182 - val_loss: 0.4846 - val_acc: 0.7143\n",
      "Epoch 847/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4269 - acc: 0.8182 - val_loss: 0.4829 - val_acc: 0.7143\n",
      "Epoch 848/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4280 - acc: 0.8242 - val_loss: 0.4782 - val_acc: 0.7143\n",
      "Epoch 849/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4364 - acc: 0.790 - 0s - loss: 0.4268 - acc: 0.8182 - val_loss: 0.4813 - val_acc: 0.7143\n",
      "Epoch 850/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4266 - acc: 0.8182 - val_loss: 0.4832 - val_acc: 0.7143\n",
      "Epoch 851/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4263 - acc: 0.8182 - val_loss: 0.4813 - val_acc: 0.7143\n",
      "Epoch 852/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4261 - acc: 0.8182 - val_loss: 0.4823 - val_acc: 0.7143\n",
      "Epoch 853/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4259 - acc: 0.8182 - val_loss: 0.4813 - val_acc: 0.7143\n",
      "Epoch 854/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4258 - acc: 0.8182 - val_loss: 0.4826 - val_acc: 0.7143\n",
      "Epoch 855/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4256 - acc: 0.8182 - val_loss: 0.4834 - val_acc: 0.7143\n",
      "Epoch 856/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4255 - acc: 0.8182 - val_loss: 0.4821 - val_acc: 0.7143\n",
      "Epoch 857/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4254 - acc: 0.8182 - val_loss: 0.4837 - val_acc: 0.7143\n",
      "Epoch 858/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4252 - acc: 0.8182 - val_loss: 0.4820 - val_acc: 0.7143\n",
      "Epoch 859/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4250 - acc: 0.8182 - val_loss: 0.4829 - val_acc: 0.7143\n",
      "Epoch 860/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4248 - acc: 0.8182 - val_loss: 0.4825 - val_acc: 0.7143\n",
      "Epoch 861/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4248 - acc: 0.8182 - val_loss: 0.4832 - val_acc: 0.7143\n",
      "Epoch 862/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4245 - acc: 0.8182 - val_loss: 0.4822 - val_acc: 0.7143\n",
      "Epoch 863/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4243 - acc: 0.8182 - val_loss: 0.4822 - val_acc: 0.7143\n",
      "Epoch 864/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4243 - acc: 0.8182 - val_loss: 0.4805 - val_acc: 0.7143\n",
      "Epoch 865/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4241 - acc: 0.8182 - val_loss: 0.4813 - val_acc: 0.7143\n",
      "Epoch 866/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4239 - acc: 0.8182 - val_loss: 0.4815 - val_acc: 0.7143\n",
      "Epoch 867/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4243 - acc: 0.8182 - val_loss: 0.4779 - val_acc: 0.7143\n",
      "Epoch 868/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4241 - acc: 0.8182 - val_loss: 0.4755 - val_acc: 0.7381\n",
      "Epoch 869/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4236 - acc: 0.8182 - val_loss: 0.4753 - val_acc: 0.7381\n",
      "Epoch 870/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4366 - acc: 0.830 - 0s - loss: 0.4233 - acc: 0.8182 - val_loss: 0.4759 - val_acc: 0.7143\n",
      "Epoch 871/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4233 - acc: 0.8182 - val_loss: 0.4779 - val_acc: 0.7143\n",
      "Epoch 872/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4250 - acc: 0.8182 - val_loss: 0.4838 - val_acc: 0.7143\n",
      "Epoch 873/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4235 - acc: 0.8182 - val_loss: 0.4854 - val_acc: 0.7143\n",
      "Epoch 874/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4227 - acc: 0.8242 - val_loss: 0.4834 - val_acc: 0.7143\n",
      "Epoch 875/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4228 - acc: 0.8242 - val_loss: 0.4798 - val_acc: 0.7143\n",
      "Epoch 876/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4224 - acc: 0.8182 - val_loss: 0.4788 - val_acc: 0.7143\n",
      "Epoch 877/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4224 - acc: 0.8182 - val_loss: 0.4767 - val_acc: 0.7143\n",
      "Epoch 878/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4226 - acc: 0.8182 - val_loss: 0.4741 - val_acc: 0.7381\n",
      "Epoch 879/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4221 - acc: 0.8182 - val_loss: 0.4766 - val_acc: 0.7143\n",
      "Epoch 880/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4219 - acc: 0.8182 - val_loss: 0.4782 - val_acc: 0.7143\n",
      "Epoch 881/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4220 - acc: 0.8182 - val_loss: 0.4806 - val_acc: 0.7143\n",
      "Epoch 882/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4218 - acc: 0.8182 - val_loss: 0.4820 - val_acc: 0.7143\n",
      "Epoch 883/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4214 - acc: 0.8242 - val_loss: 0.4797 - val_acc: 0.7143\n",
      "Epoch 884/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4218 - acc: 0.8242 - val_loss: 0.4756 - val_acc: 0.7143\n",
      "Epoch 885/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4214 - acc: 0.8182 - val_loss: 0.4783 - val_acc: 0.7143\n",
      "Epoch 886/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4215 - acc: 0.8242 - val_loss: 0.4743 - val_acc: 0.7381\n",
      "Epoch 887/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4370 - acc: 0.810 - 0s - loss: 0.4207 - acc: 0.8182 - val_loss: 0.4740 - val_acc: 0.7381\n",
      "Epoch 888/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4207 - acc: 0.8242 - val_loss: 0.4732 - val_acc: 0.7381\n",
      "Epoch 889/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4204 - acc: 0.8182 - val_loss: 0.4745 - val_acc: 0.7381\n",
      "Epoch 890/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4203 - acc: 0.8182 - val_loss: 0.4743 - val_acc: 0.7381\n",
      "Epoch 891/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4206 - acc: 0.8182 - val_loss: 0.4768 - val_acc: 0.7143\n",
      "Epoch 892/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4200 - acc: 0.8242 - val_loss: 0.4772 - val_acc: 0.7143\n",
      "Epoch 893/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4199 - acc: 0.8242 - val_loss: 0.4761 - val_acc: 0.7143\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4199 - acc: 0.8242 - val_loss: 0.4772 - val_acc: 0.7143\n",
      "Epoch 895/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4197 - acc: 0.8242 - val_loss: 0.4751 - val_acc: 0.7143\n",
      "Epoch 896/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4194 - acc: 0.8242 - val_loss: 0.4757 - val_acc: 0.7143\n",
      "Epoch 897/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4193 - acc: 0.8242 - val_loss: 0.4765 - val_acc: 0.7143\n",
      "Epoch 898/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4191 - acc: 0.8242 - val_loss: 0.4759 - val_acc: 0.7143\n",
      "Epoch 899/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4190 - acc: 0.8242 - val_loss: 0.4750 - val_acc: 0.7143\n",
      "Epoch 900/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4205 - acc: 0.8242 - val_loss: 0.4697 - val_acc: 0.7381\n",
      "Epoch 901/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4190 - acc: 0.8182 - val_loss: 0.4693 - val_acc: 0.7381\n",
      "Epoch 902/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4196 - acc: 0.8182 - val_loss: 0.4670 - val_acc: 0.7381\n",
      "Epoch 903/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4188 - acc: 0.8242 - val_loss: 0.4712 - val_acc: 0.7381\n",
      "Epoch 904/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4187 - acc: 0.8182 - val_loss: 0.4695 - val_acc: 0.7381\n",
      "Epoch 905/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4182 - acc: 0.8182 - val_loss: 0.4714 - val_acc: 0.7381\n",
      "Epoch 906/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4180 - acc: 0.8242 - val_loss: 0.4710 - val_acc: 0.7381\n",
      "Epoch 907/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4180 - acc: 0.8182 - val_loss: 0.4731 - val_acc: 0.7381\n",
      "Epoch 908/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4180 - acc: 0.8242 - val_loss: 0.4756 - val_acc: 0.7143\n",
      "Epoch 909/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4177 - acc: 0.8242 - val_loss: 0.4730 - val_acc: 0.7381\n",
      "Epoch 910/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4176 - acc: 0.8242 - val_loss: 0.4749 - val_acc: 0.7143\n",
      "Epoch 911/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4172 - acc: 0.8242 - val_loss: 0.4742 - val_acc: 0.7143\n",
      "Epoch 912/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4171 - acc: 0.8242 - val_loss: 0.4729 - val_acc: 0.7381\n",
      "Epoch 913/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4169 - acc: 0.8242 - val_loss: 0.4724 - val_acc: 0.7381\n",
      "Epoch 914/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4168 - acc: 0.8242 - val_loss: 0.4717 - val_acc: 0.7381\n",
      "Epoch 915/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4167 - acc: 0.8242 - val_loss: 0.4731 - val_acc: 0.7381\n",
      "Epoch 916/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4165 - acc: 0.8242 - val_loss: 0.4733 - val_acc: 0.7381\n",
      "Epoch 917/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4167 - acc: 0.8242 - val_loss: 0.4752 - val_acc: 0.7143\n",
      "Epoch 918/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4182 - acc: 0.8242 - val_loss: 0.4800 - val_acc: 0.7143\n",
      "Epoch 919/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4164 - acc: 0.8242 - val_loss: 0.4759 - val_acc: 0.7143\n",
      "Epoch 920/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4166 - acc: 0.8242 - val_loss: 0.4717 - val_acc: 0.7381\n",
      "Epoch 921/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4158 - acc: 0.8242 - val_loss: 0.4727 - val_acc: 0.7381\n",
      "Epoch 922/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4160 - acc: 0.8242 - val_loss: 0.4747 - val_acc: 0.7143\n",
      "Epoch 923/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4156 - acc: 0.8242 - val_loss: 0.4729 - val_acc: 0.7381\n",
      "Epoch 924/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4160 - acc: 0.8242 - val_loss: 0.4692 - val_acc: 0.7381\n",
      "Epoch 925/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4154 - acc: 0.8242 - val_loss: 0.4689 - val_acc: 0.7381\n",
      "Epoch 926/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4153 - acc: 0.8242 - val_loss: 0.4713 - val_acc: 0.7381\n",
      "Epoch 927/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4151 - acc: 0.8242 - val_loss: 0.4697 - val_acc: 0.7381\n",
      "Epoch 928/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4149 - acc: 0.8242 - val_loss: 0.4705 - val_acc: 0.7381\n",
      "Epoch 929/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4152 - acc: 0.8242 - val_loss: 0.4735 - val_acc: 0.7381\n",
      "Epoch 930/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4148 - acc: 0.8242 - val_loss: 0.4746 - val_acc: 0.7143\n",
      "Epoch 931/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.4510 - acc: 0.820 - 0s - loss: 0.4144 - acc: 0.8242 - val_loss: 0.4726 - val_acc: 0.7381\n",
      "Epoch 932/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4147 - acc: 0.8242 - val_loss: 0.4748 - val_acc: 0.7143\n",
      "Epoch 933/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4144 - acc: 0.8242 - val_loss: 0.4752 - val_acc: 0.7143\n",
      "Epoch 934/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4146 - acc: 0.8242 - val_loss: 0.4770 - val_acc: 0.7143\n",
      "Epoch 935/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4153 - acc: 0.8242 - val_loss: 0.4798 - val_acc: 0.7143\n",
      "Epoch 936/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4139 - acc: 0.8303 - val_loss: 0.4764 - val_acc: 0.7143\n",
      "Epoch 937/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4138 - acc: 0.8242 - val_loss: 0.4731 - val_acc: 0.7381\n",
      "Epoch 938/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4135 - acc: 0.8242 - val_loss: 0.4714 - val_acc: 0.7381\n",
      "Epoch 939/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4135 - acc: 0.8242 - val_loss: 0.4696 - val_acc: 0.7381\n",
      "Epoch 940/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4133 - acc: 0.8242 - val_loss: 0.4712 - val_acc: 0.7381\n",
      "Epoch 941/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4132 - acc: 0.8242 - val_loss: 0.4727 - val_acc: 0.7381\n",
      "Epoch 942/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4132 - acc: 0.8242 - val_loss: 0.4693 - val_acc: 0.7381\n",
      "Epoch 943/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4128 - acc: 0.8242 - val_loss: 0.4680 - val_acc: 0.7381\n",
      "Epoch 944/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4128 - acc: 0.8242 - val_loss: 0.4665 - val_acc: 0.7381\n",
      "Epoch 945/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4125 - acc: 0.8242 - val_loss: 0.4674 - val_acc: 0.7381\n",
      "Epoch 946/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4134 - acc: 0.8303 - val_loss: 0.4721 - val_acc: 0.7381\n",
      "Epoch 947/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4124 - acc: 0.8242 - val_loss: 0.4728 - val_acc: 0.7381\n",
      "Epoch 948/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4121 - acc: 0.8242 - val_loss: 0.4716 - val_acc: 0.7381\n",
      "Epoch 949/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4124 - acc: 0.8242 - val_loss: 0.4678 - val_acc: 0.7381\n",
      "Epoch 950/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4125 - acc: 0.8242 - val_loss: 0.4644 - val_acc: 0.7381\n",
      "Epoch 951/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4116 - acc: 0.8303 - val_loss: 0.4653 - val_acc: 0.7381\n",
      "Epoch 952/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4116 - acc: 0.8303 - val_loss: 0.4669 - val_acc: 0.7381\n",
      "Epoch 953/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4117 - acc: 0.8303 - val_loss: 0.4698 - val_acc: 0.7381\n",
      "Epoch 954/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4112 - acc: 0.8242 - val_loss: 0.4688 - val_acc: 0.7381\n",
      "Epoch 955/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4113 - acc: 0.8242 - val_loss: 0.4695 - val_acc: 0.7381\n",
      "Epoch 956/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4111 - acc: 0.8242 - val_loss: 0.4673 - val_acc: 0.7381\n",
      "Epoch 957/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4116 - acc: 0.8242 - val_loss: 0.4633 - val_acc: 0.7381\n",
      "Epoch 958/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s - loss: 0.4108 - acc: 0.8303 - val_loss: 0.4633 - val_acc: 0.7381\n",
      "Epoch 959/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4110 - acc: 0.8303 - val_loss: 0.4617 - val_acc: 0.7381\n",
      "Epoch 960/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4114 - acc: 0.8364 - val_loss: 0.4673 - val_acc: 0.7381\n",
      "Epoch 961/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4103 - acc: 0.8242 - val_loss: 0.4681 - val_acc: 0.7381\n",
      "Epoch 962/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4102 - acc: 0.8242 - val_loss: 0.4664 - val_acc: 0.7381\n",
      "Epoch 963/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4100 - acc: 0.8303 - val_loss: 0.4675 - val_acc: 0.7381\n",
      "Epoch 964/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4110 - acc: 0.8364 - val_loss: 0.4718 - val_acc: 0.7381\n",
      "Epoch 965/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4102 - acc: 0.8242 - val_loss: 0.4726 - val_acc: 0.7381\n",
      "Epoch 966/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4099 - acc: 0.8242 - val_loss: 0.4716 - val_acc: 0.7381\n",
      "Epoch 967/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4095 - acc: 0.8242 - val_loss: 0.4694 - val_acc: 0.7381\n",
      "Epoch 968/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4094 - acc: 0.8242 - val_loss: 0.4673 - val_acc: 0.7381\n",
      "Epoch 969/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4096 - acc: 0.8242 - val_loss: 0.4641 - val_acc: 0.7381\n",
      "Epoch 970/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4090 - acc: 0.8303 - val_loss: 0.4646 - val_acc: 0.7381\n",
      "Epoch 971/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4090 - acc: 0.8303 - val_loss: 0.4643 - val_acc: 0.7381\n",
      "Epoch 972/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4089 - acc: 0.8303 - val_loss: 0.4634 - val_acc: 0.7381\n",
      "Epoch 973/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4087 - acc: 0.8303 - val_loss: 0.4637 - val_acc: 0.7381\n",
      "Epoch 974/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4089 - acc: 0.8303 - val_loss: 0.4669 - val_acc: 0.7381\n",
      "Epoch 975/1000\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.3842 - acc: 0.870 - 0s - loss: 0.4087 - acc: 0.8303 - val_loss: 0.4639 - val_acc: 0.7381\n",
      "Epoch 976/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4082 - acc: 0.8303 - val_loss: 0.4642 - val_acc: 0.7381\n",
      "Epoch 977/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4084 - acc: 0.8303 - val_loss: 0.4619 - val_acc: 0.7381\n",
      "Epoch 978/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4080 - acc: 0.8303 - val_loss: 0.4636 - val_acc: 0.7381\n",
      "Epoch 979/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4078 - acc: 0.8303 - val_loss: 0.4631 - val_acc: 0.7381\n",
      "Epoch 980/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4077 - acc: 0.8303 - val_loss: 0.4628 - val_acc: 0.7381\n",
      "Epoch 981/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4082 - acc: 0.8364 - val_loss: 0.4666 - val_acc: 0.7381\n",
      "Epoch 982/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4076 - acc: 0.8303 - val_loss: 0.4675 - val_acc: 0.7381\n",
      "Epoch 983/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4077 - acc: 0.8303 - val_loss: 0.4642 - val_acc: 0.7381\n",
      "Epoch 984/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4073 - acc: 0.8303 - val_loss: 0.4626 - val_acc: 0.7381\n",
      "Epoch 985/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4092 - acc: 0.8242 - val_loss: 0.4693 - val_acc: 0.7381\n",
      "Epoch 986/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4071 - acc: 0.8303 - val_loss: 0.4676 - val_acc: 0.7381\n",
      "Epoch 987/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4070 - acc: 0.8303 - val_loss: 0.4681 - val_acc: 0.7381\n",
      "Epoch 988/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4068 - acc: 0.8303 - val_loss: 0.4684 - val_acc: 0.7381\n",
      "Epoch 989/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4068 - acc: 0.8303 - val_loss: 0.4653 - val_acc: 0.7381\n",
      "Epoch 990/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4064 - acc: 0.8303 - val_loss: 0.4653 - val_acc: 0.7381\n",
      "Epoch 991/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4063 - acc: 0.8303 - val_loss: 0.4636 - val_acc: 0.7381\n",
      "Epoch 992/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4061 - acc: 0.8303 - val_loss: 0.4628 - val_acc: 0.7381\n",
      "Epoch 993/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4064 - acc: 0.8303 - val_loss: 0.4602 - val_acc: 0.7381\n",
      "Epoch 994/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4060 - acc: 0.8303 - val_loss: 0.4600 - val_acc: 0.7381\n",
      "Epoch 995/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4061 - acc: 0.8303 - val_loss: 0.4582 - val_acc: 0.7381\n",
      "Epoch 996/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4057 - acc: 0.8303 - val_loss: 0.4602 - val_acc: 0.7381\n",
      "Epoch 997/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4056 - acc: 0.8303 - val_loss: 0.4613 - val_acc: 0.7381\n",
      "Epoch 998/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4054 - acc: 0.8303 - val_loss: 0.4620 - val_acc: 0.7381\n",
      "Epoch 999/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4060 - acc: 0.8303 - val_loss: 0.4582 - val_acc: 0.7381\n",
      "Epoch 1000/1000\n",
      "165/165 [==============================] - 0s - loss: 0.4051 - acc: 0.8303 - val_loss: 0.4592 - val_acc: 0.7381\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
